{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Signal_generator.generate_signal import generate_X_matrix\n",
    "from Algorithmes.beamforming import beamforming_method\n",
    "from Signal_generator.generate_signal import generate_A_matrix\n",
    "from Signal_generator.generate_signal import generate_S_matrix\n",
    "from Signal_generator.generate_signal import generate_noise\n",
    "from Signal_generator.generate_signal import generate_R_hat\n",
    "from Signal_generator.generate_signal import generate_R_hat_with_phase\n",
    "from Algorithmes.music import music_method\n",
    "from Algorithmes.music import estimate_angles\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import itertools\n",
    "from torchsummary import summary\n",
    "from numpy.linalg import eigh\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from Algorithmes.music import generate_steering_vector\n",
    "from Plots.draw_plot import plot_single_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():  \n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_music_spectrum(R_hat, nbSensors, nbSources, angles_range):\n",
    "    # Calculer les vecteurs propres et les valeurs propres\n",
    "    _, eigenvectors = np.linalg.eigh(R_hat)\n",
    "    # Sélectionner les k plus grandes valeurs propres\n",
    "    noise_subspace = eigenvectors[:, :-nbSources]\n",
    "    music_spectrum = np.zeros_like(angles_range, dtype=float)\n",
    "    for idx, theta in enumerate(angles_range):\n",
    "        steering_vector = generate_steering_vector(nbSensors, theta)\n",
    "        music_spectrum[idx] = 1 / np.linalg.norm(noise_subspace.conj().T @ steering_vector)\n",
    "\n",
    "    return music_spectrum\n",
    "\n",
    "perturbation_parameter_sd = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def generate_combinations(phi_max, rho, nb_sources):\n",
    "    \"\"\"Cette fonction sert à générer toutes les combinaisons d'angles possibles dans la plage de résolution\"\"\"\n",
    "    # Générer une plage de valeurs possibles pour les signaux\n",
    "    values = list(range(-int(phi_max / rho), int(phi_max / rho) + 1))\n",
    "    \n",
    "    # Générer toutes les combinaisons possibles de signaux\n",
    "    all_combinations = list(itertools.product(values, repeat=nb_sources))\n",
    "    \n",
    "    # Supprimer les combinaisons où l'ordre ne compte pas et où deux signaux ont la même valeur\n",
    "    unique_combinations = {tuple(sorted(combination)) for combination in all_combinations if len(set(combination)) == nb_sources}\n",
    "    \n",
    "    return list(unique_combinations)\n",
    "\n",
    "#\n",
    "Q = 4\n",
    "N = 2**12\n",
    "phi_max = 60\n",
    "rho = 1\n",
    "nbSources = 2 # Nombre de sources\n",
    "nbSensors = 9 # Nombre de capteurs\n",
    "nbTimePoints = 100 # Nombre de points temporels\n",
    "signal_noise_ratio = 10 # Rapport signal sur bruit en décibels. Si 'False', cela revient à une absence totale de bruit.\n",
    "theta1 = -20 # Angle entre la perpendiculaire à la ligne de capteurs, et la source 1\n",
    "theta2 = 20 # Angle entre la perpendiculaire à la ligne de capteurs, et la source 2\n",
    "var_ratio = [1] # Liste qui donne le rapport entre la variance du signal 1 et celui des autres sources (ex: [2, 3] signifie que la source 2 a une variance 2 fois plus grande que la source 1, et la source 3 a une variance 3 fois plus grande que la source 1)\n",
    "correlation_List = [0] # Liste des corrélations. Il y a une corrélation nécéssaire pour chaque paire distincte de sources différentes: 0 pour 1 source, 1 pour 2 sources, 3 pour 3 sources, 6 pour 4 sources etc...\n",
    "# Ordre de remplisage de la correlation_List: de gauche à droite et ligne par ligne, moitié haut-droite de la matrice uniquement, puis symétrie de ces valeurs pour la moitié bas-gauche\n",
    "perturbation_parameter_sd = 0 # Écart-type de la distribution normale qui génère les erreurs de calibration des capteurs\n",
    "J_alpha = 100\n",
    "J_beta = 10\n",
    "\n",
    "def generate_deepmusic_partitioned_data(J_alpha, J_beta, nbSensors, nbSources, T, SNR_TRAIN, Q, N, phi_max, rho, correlation_List, var_ratio):\n",
    "    training_data_sets = [[] for _ in range(Q)]\n",
    "    full_theta = np.linspace(-phi_max, phi_max, N)\n",
    "    L = N // Q\n",
    "\n",
    "    for signal_noise_ratio in SNR_TRAIN:\n",
    "        for j_alpha in range(J_alpha):\n",
    "            # Répartir les sources dans les sous-régions\n",
    "            source_angles = []\n",
    "            for q in range(min(Q, nbSources)):\n",
    "                # Déterminer les limites de la sous-région\n",
    "                start_theta = -phi_max + q * (2 * phi_max / Q)\n",
    "                end_theta = start_theta + (2 * phi_max / Q)\n",
    "                # Générer un angle aléatoire dans la sous-région\n",
    "                angle = np.random.uniform(start_theta, end_theta)\n",
    "                source_angles.append(angle)\n",
    "\n",
    "            for j_beta in range(J_beta):\n",
    "                varList = np.ones(nbSources).tolist()\n",
    "                correlation_List = np.zeros(nbSources * (nbSources - 1) // 2).tolist()\n",
    "                X = generate_X_matrix(nbSources=nbSources, nbSensors=nbSensors, nbTimePoints=T, thetaList=source_angles, var_ratio=var_ratio, correlation_List=correlation_List, signal_noise_ratio=signal_noise_ratio, perturbation_parameter_sd=0)\n",
    "                R_hat = generate_R_hat(X)\n",
    "                R_hat_with_phase = generate_R_hat_with_phase(X)\n",
    "                \n",
    "                full_music_spectrum = calculate_music_spectrum(R_hat, nbSensors, nbSources, full_theta)\n",
    "\n",
    "                for q in range(Q):\n",
    "                    # Sampling MUSIC spectrum for the q-th subregion\n",
    "                    start_index = q * L\n",
    "                    end_index = (q + 1) * L if q != Q - 1 else N\n",
    "                    pq = full_music_spectrum[start_index:end_index]\n",
    "                \n",
    "                    input_data = R_hat_with_phase\n",
    "                    output_data = pq\n",
    "                    training_data_sets[q].append((input_data, output_data))\n",
    "\n",
    "    return training_data_sets\n",
    "\n",
    "\n",
    "full_theta = np.linspace(- phi_max , phi_max, N)\n",
    "# Example usage\n",
    "SNR_TRAIN = [0]  # Different SNR levels for training\n",
    "training_datasets = generate_deepmusic_partitioned_data(J_alpha=J_alpha,J_beta=J_beta,nbSensors=nbSensors, nbSources=nbSources, T=nbTimePoints, SNR_TRAIN=SNR_TRAIN, Q=Q, N=N, phi_max=phi_max, rho=rho, correlation_List=correlation_List, var_ratio=var_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_datasets[0][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[698.6950068869792, 1663.1218260868106]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subinterval_length = N//Q\n",
    "thetaList = [np.random.uniform(-phi_max + q * subinterval_length, -phi_max + (q + 1) * subinterval_length) for q in range(nbSources)]\n",
    "thetaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m input_data, output_data \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m978\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,Q\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "input_data, output_data = training_datasets[1][978]\n",
    "a = []\n",
    "for i in range(0,Q-1):\n",
    "    input_data, output_data = training_datasets[i][978]\n",
    "    a.append(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 35\u001b[0m\n\u001b[0;32m     30\u001b[0m         reconstructed_spectrum[start_index:end_index] \u001b[38;5;241m=\u001b[39m segment\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reconstructed_spectrum\n\u001b[1;32m---> 35\u001b[0m reconstruct_music_spectrum(\u001b[43ma\u001b[49m, Q, N)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(a))\n\u001b[0;32m     37\u001b[0m plot_single_music(reconstruct_music_spectrum(a, Q, N),np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m60\u001b[39m,\u001b[38;5;241m60\u001b[39m,N))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "def reconstruct_music_spectrum(segments, Q, N):\n",
    "    \"\"\"\n",
    "    Reconstruct the full music spectrum from its segmented parts.\n",
    "\n",
    "    Args:\n",
    "    segments (list of ndarrays): The segmented parts of the music spectrum.\n",
    "    Q (int): The number of segments.\n",
    "    N (int): The total number of points in the full music spectrum.\n",
    "\n",
    "    Returns:\n",
    "    ndarray: The reconstructed music spectrum.\n",
    "    \"\"\"\n",
    "    # Initialize the reconstructed spectrum with zeros\n",
    "    reconstructed_spectrum = np.zeros(N, dtype=float)\n",
    "    \n",
    "    # Length of each segment\n",
    "    segment_length = N // Q\n",
    "\n",
    "    # Iterate over each segment and place it in the reconstructed spectrum\n",
    "    for q, segment in enumerate(segments):\n",
    "        start_index = q * segment_length\n",
    "        if q < Q - 1:\n",
    "            # For all but the last segment, use the segment length\n",
    "            end_index = start_index + segment_length\n",
    "        else:\n",
    "            # For the last segment, it can be longer if N is not divisible by Q\n",
    "            end_index = N\n",
    "        # Make sure segment is the correct shape\n",
    "        segment = segment[:end_index - start_index]\n",
    "        reconstructed_spectrum[start_index:end_index] = segment\n",
    "    \n",
    "    return reconstructed_spectrum\n",
    "    \n",
    "\n",
    "reconstruct_music_spectrum(a, Q, N)\n",
    "print(type(a))\n",
    "plot_single_music(reconstruct_music_spectrum(a, Q, N),np.linspace(-60,60,N))\n",
    "for i in range(0,Q-1):\n",
    "    input_data, output_data = training_datasets[i][978]\n",
    "    plot_single_music(output_data,np.linspace(-60,60,N//Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(training_data_sets):\n",
    "    # Calculer la moyenne et l'écart-type pour la normalisation\n",
    "    all_data = np.concatenate([data[0] for q_data in training_data_sets for data in q_data], axis=0)\n",
    "    mean = np.mean(all_data, axis=(0, 2), keepdims=True)\n",
    "    std = np.std(all_data, axis=(0, 2), keepdims=True)\n",
    "\n",
    "    # Normaliser les données\n",
    "    normalized_training_data_sets = []\n",
    "    for q_data in training_data_sets:\n",
    "        normalized_q_data = []\n",
    "        for input_data, output_data in q_data:\n",
    "            normalized_input = (input_data - mean) / std\n",
    "            normalized_q_data.append((normalized_input, output_data))\n",
    "        normalized_training_data_sets.append(normalized_q_data)\n",
    "\n",
    "    return normalized_training_data_sets\n",
    "\n",
    "# Exemple d'utilisation\n",
    "normalized_training_datasets = normalize_data(training_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.333333333333333\n",
      "640\n",
      "1.3333333333333333\n",
      "160\n",
      "1.6666666666666667\n",
      "200\n",
      "5.333333333333333\n",
      "640\n",
      "1.3333333333333333\n",
      "160\n",
      "1.6666666666666667\n",
      "200\n",
      "5.333333333333333\n",
      "640\n",
      "1.3333333333333333\n",
      "160\n",
      "1.6666666666666667\n",
      "200\n",
      "5.333333333333333\n",
      "640\n",
      "1.3333333333333333\n",
      "160\n",
      "1.6666666666666667\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class DeepMusicDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_data, output_data = self.data[idx]\n",
    "        return torch.tensor(input_data, dtype=torch.float32), torch.tensor(output_data, dtype=torch.float32)\n",
    "\n",
    "def create_loaders_for_subregion(data, batch_size=120, validation_split=0.2, test_split=0.2):\n",
    "    # Séparation des données en ensembles d'entraînement, de validation et de test\n",
    "    train_data, test_data = train_test_split(data, test_size=test_split, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_data, test_size=validation_split, random_state=42)\n",
    "\n",
    "    # Création des instances de DeepMusicDataset\n",
    "    train_dataset = DeepMusicDataset(train_data)\n",
    "    print(len(train_dataset)/batch_size)\n",
    "    print(len(train_dataset))\n",
    "    val_dataset = DeepMusicDataset(val_data)\n",
    "    print(len(val_dataset)/batch_size)\n",
    "    print(len(val_dataset))\n",
    "    test_dataset = DeepMusicDataset(test_data)\n",
    "    print(len(test_dataset)/batch_size)\n",
    "    print(len(test_dataset))\n",
    "\n",
    "    # Création des DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Création des DataLoader pour chaque sous-région\n",
    "loaders_per_subregion = [create_loaders_for_subregion(normalized_training_datasets[q]) for q in range(Q)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeepMusicModel(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(DeepMusicModel, self).__init__()\n",
    "        # Define the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the fourth convolutional layer\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Global average pooling layer\n",
    "        self.global_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(256, 4096)\n",
    "        self.fc2= nn.Linear(in_features=4096, out_features=2048)\n",
    "        self.fc3 = nn.Linear(in_features=2048, out_features=1024)\n",
    "        self.fc4 = nn.Linear(in_features=1024, out_features=output_size)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "        # Softmax layer \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the first convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # Apply the second convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        \n",
    "        # Apply the third convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Apply the fourth convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        # Apply global average pooling\n",
    "        x = self.global_pooling(x)\n",
    "        \n",
    "        # Reshape for the fully connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Apply the fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        # Apply the dropout layer\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Apply the softmax layer\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#Définition du device\n",
    "\n",
    "device = (\n",
    "    \"gpu\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8\n",
      "Early stopping at epoch 4\n",
      "Early stopping at epoch 4\n",
      "Early stopping at epoch 6\n",
      "Training time: 22.779598474502563 seconds\n",
      "Average MSE per epoch on validation set: [0.6092191845178604, 0.6072463139891624, 0.5270665533840656, 0.5304759681224823, 0.5296136200428009, 0.5288704015314579, 0.5247805006802082, 0.5237041510641575, 0.4418217405676842, 0.44349342584609985]\n",
      "Average MSE per epoch on training set: [0.5826438019673029, 0.5826438019673029, 0.5213162936270237, 0.5213162638247013, 0.5213162377476692, 0.5213162936270237, 0.5158897861838341, 0.5158897861838341, 0.4151046760380268, 0.4151046797633171]\n",
      "Average Training Loss: 0.5340\n",
      "Average Validation Loss: 0.5177\n",
      "MSE on Test Set: 0.4895\n",
      "Training time: 22.779598474502563\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_accuracy(predicted_spectrum, target_spectrum, angles_range, nbSources, peak_tolerance):\n",
    "    \"\"\"\n",
    "    Calculate accuracy for a single predicted and target spectrum.\n",
    "    \n",
    "    :param predicted_spectrum: Predicted MUSIC spectrum (1D NumPy array).\n",
    "    :param target_spectrum: True MUSIC spectrum (1D NumPy array).\n",
    "    :param angles_range: The range of angles over which the MUSIC spectrum is calculated.\n",
    "    :param nbSources: The number of sources (peaks) to consider.\n",
    "    :param peak_tolerance: The tolerance for considering a predicted peak to match a target peak.\n",
    "    :return: Accuracy as a float.\n",
    "    \"\"\"\n",
    "    # Estimate angles from the predicted and target spectra\n",
    "    estimated_angles = estimate_angles(nbSources, predicted_spectrum, angles_range)\n",
    "    true_angles = estimate_angles(nbSources, target_spectrum, angles_range)\n",
    "\n",
    "    # Compare the estimated angles with the true angles\n",
    "    correct_predictions = sum(1 for est_angle in estimated_angles if np.any(np.abs(true_angles - est_angle) <= peak_tolerance))\n",
    "    accuracy = correct_predictions / nbSources if nbSources > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate_spectrum(loaders_per_subregion, epochs, nbSources, angles_range, peak_tolerance=5):\n",
    "    models = []\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    val_mse_list = []\n",
    "    metrics = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_mse': [],\n",
    "        'avg_mse_per_epoch_val': [],\n",
    "        'avg_mse_per_epoch_train': [],\n",
    "        'total_mse': None,\n",
    "        'training_time': None\n",
    "    }\n",
    "\n",
    "    # Training configuration\n",
    "    initial_lr = 0.1\n",
    "    lr_decay_factor = 0.5\n",
    "    lr_decay_epoch = 10\n",
    "    early_stopping_patience = 3\n",
    "\n",
    "    start_time = time.time()  # Start time for training\n",
    "    for train_loader, val_loader, test_loader in loaders_per_subregion:\n",
    "        model = DeepMusicModel(N//Q)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        best_val_mse = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Adjust learning rate\n",
    "            if epoch % lr_decay_epoch == 0 and epoch > 0:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] *= lr_decay_factor\n",
    "\n",
    "            # Training loop\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets).item()\n",
    "                optimizer.step()\n",
    "                train_loss += loss\n",
    "                \n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            train_loss_list.append(avg_train_loss)\n",
    "            metrics[\"train_loss\"].append(avg_train_loss)\n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss, val_mse = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    outputs = model(inputs)\n",
    "                    val_loss += criterion(outputs, targets).item()\n",
    "                    val_mse += F.mse_loss(outputs, targets).item()\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            avg_val_mse = val_mse / len(val_loader)\n",
    "            val_loss_list.append(avg_val_loss)\n",
    "            metrics[\"val_loss\"].append(avg_val_loss)\n",
    "            val_mse_list.append(avg_val_mse)\n",
    "            metrics[\"val_mse\"].append(avg_val_mse)\n",
    "\n",
    "            # Early stopping\n",
    "            if avg_val_mse < best_val_mse:\n",
    "                best_val_mse = avg_val_mse\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve == early_stopping_patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    # Calculate training time\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training time: {training_time} seconds\")\n",
    "\n",
    "    # Test set evaluation\n",
    "    concatenated_outputs = []\n",
    "    concatenated_targets = []\n",
    "\n",
    "    for model, test_loader in zip(models, [x[2] for x in loaders_per_subregion]):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Concatenate outputs and targets\n",
    "                concatenated_outputs.append(outputs)\n",
    "                concatenated_targets.append(targets)\n",
    "\n",
    "    # Calculate the average MSE per epoch on the validation set\n",
    "    avg_mse_per_epoch_val = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_mse = []\n",
    "        for i, model in enumerate(models):\n",
    "            # Determine the actual number of epochs the model was trained for\n",
    "            actual_epochs = len(train_loss_list[i * epochs:(i + 1) * epochs])\n",
    "            if epoch < actual_epochs:\n",
    "                epoch_mse.append(train_loss_list[i * epochs + epoch])\n",
    "        avg_mse_per_epoch_val.append(np.mean(epoch_mse))\n",
    "        metrics[\"avg_mse_per_epoch_train\"].append(np.mean(epoch_mse))\n",
    "        \n",
    "\n",
    "    print(\"Average MSE per epoch on validation set:\", avg_mse_per_epoch_val)\n",
    "\n",
    "    # Calculate the average MSE per epoch on the training set\n",
    "    avg_mse_per_epoch_train = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_mse = []\n",
    "        for i, model in enumerate(models):\n",
    "            # Determine the actual number of epochs the model was trained for\n",
    "            actual_epochs = len(val_mse_list[i * epochs:(i + 1) * epochs])\n",
    "            if epoch < actual_epochs:\n",
    "                epoch_mse.append(val_mse_list[i * epochs + epoch])\n",
    "        avg_mse_per_epoch_train.append(np.mean(epoch_mse))\n",
    "        metrics[\"avg_mse_per_epoch_train\"].append(np.mean(epoch_mse))\n",
    "\n",
    "    print(\"Average MSE per epoch on training set:\", avg_mse_per_epoch_train)\n",
    "\n",
    "    # Determine the maximum size of all targets\n",
    "    max_size = max(target.size(1) for target in concatenated_targets)\n",
    "    # Pad each target tensor to the maximum size\n",
    "    padded_targets = [F.pad(target, (0, max_size - target.size(1))) for target in concatenated_targets]\n",
    "\n",
    "    padded_outputs = [F.pad(output, (0, max_size - output.size(1))) for output in concatenated_outputs]\n",
    "\n",
    "    # Concatenate the padded targets into a single tensor\n",
    "    concatenated_targets = torch.cat(padded_targets, dim=0)\n",
    "    concatenated_outputs = torch.cat(padded_outputs, dim=0)\n",
    "\n",
    "    # Compute MSE for concatenated outputs and targets\n",
    "    total_mse = F.mse_loss(concatenated_outputs, concatenated_targets).item()\n",
    "    metrics['total_mse'] = total_mse\n",
    "    metrics['training_time'] = training_time\n",
    "    print(f'Average Training Loss: {np.mean(train_loss_list):.4f}')\n",
    "    print(f'Average Validation Loss: {np.mean(val_loss_list):.4f}')\n",
    "    print(f'MSE on Test Set: {total_mse:.4f}')\n",
    "    print(f'Training time: {training_time}')\n",
    "    return models, metrics\n",
    "# Example usage\n",
    "model1_results = train_and_evaluate_spectrum(loaders_per_subregion=loaders_per_subregion, epochs=10, nbSources=nbSources, angles_range=full_theta, peak_tolerance=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:424] . unexpected pos 4817152 vs 4817048",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:619\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 619\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:853\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    852\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[1;32m--> 853\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:593] . PytorchStreamWriter failed writing file data/28: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mModels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompare\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m models, _ \u001b[38;5;241m=\u001b[39m model1_results\n\u001b[1;32m----> 3\u001b[0m \u001b[43msave_models_hyperparams_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDeepMusic_subregion_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\natha\\OneDrive\\Documents\\ENSAI 3A\\UE3 Big Data\\Indexation Web\\PFE\\Models\\compare.py:136\u001b[0m, in \u001b[0;36msave_models_hyperparams_and_metadata\u001b[1;34m(models, hyperparameters_list, metadata_list, directory_name)\u001b[0m\n\u001b[0;32m    133\u001b[0m metadata_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_dir, metadata_filename)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Save the model's state dictionary\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Save the hyperparameters in JSON format\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(hyperparams_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:618\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    615\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 618\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:466\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:424] . unexpected pos 4817152 vs 4817048"
     ]
    }
   ],
   "source": [
    "from Models.compare import *\n",
    "models, _ = model1_results\n",
    "save_models_hyperparams_and_metadata(models, hyperparameters_list=[{\"A\" : \"a\"} for _ in range(Q)], metadata_list=[{\"A\" : \"a\"} for _ in range(Q)], directory_name=\"DeepMusic_subregion_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeepMusicModel(\n",
       "   (conv1): Conv2d(3, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "   (fc1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "   (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "   (fc3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "   (fc4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.2, inplace=False)\n",
       "   (softmax): Softmax(dim=1)\n",
       " ),\n",
       " DeepMusicModel(\n",
       "   (conv1): Conv2d(3, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "   (fc1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "   (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "   (fc3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "   (fc4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.2, inplace=False)\n",
       "   (softmax): Softmax(dim=1)\n",
       " ),\n",
       " DeepMusicModel(\n",
       "   (conv1): Conv2d(3, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "   (fc1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "   (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "   (fc3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "   (fc4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.2, inplace=False)\n",
       "   (softmax): Softmax(dim=1)\n",
       " ),\n",
       " DeepMusicModel(\n",
       "   (conv1): Conv2d(3, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "   (fc1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "   (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "   (fc3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "   (fc4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.2, inplace=False)\n",
       "   (softmax): Softmax(dim=1)\n",
       " ),\n",
       " DeepMusicModel(\n",
       "   (conv1): Conv2d(3, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "   (fc1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "   (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "   (fc3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "   (fc4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.2, inplace=False)\n",
       "   (softmax): Softmax(dim=1)\n",
       " ),\n",
       " DeepMusicModel(\n",
       "   (conv1): Conv2d(3, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "   (fc1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "   (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "   (fc3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "   (fc4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.2, inplace=False)\n",
       "   (softmax): Softmax(dim=1)\n",
       " ),\n",
       " DeepMusicModel(\n",
       "   (conv1): Conv2d(3, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "   (fc1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "   (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "   (fc3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "   (fc4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.2, inplace=False)\n",
       "   (softmax): Softmax(dim=1)\n",
       " ),\n",
       " DeepMusicModel(\n",
       "   (conv1): Conv2d(3, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "   (fc1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "   (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "   (fc3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "   (fc4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.2, inplace=False)\n",
       "   (softmax): Softmax(dim=1)\n",
       " )]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n",
      "torch.Size([120, 512]) torch.Size([120, 4096])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "epochs = 10\n",
    "models = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "val_mse_list = []\n",
    "metrics = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_mse': [],\n",
    "        'avg_mse_per_epoch_val': [],\n",
    "        'avg_mse_per_epoch_train': [],\n",
    "        'total_mse': None,\n",
    "        'training_time': None\n",
    "    }\n",
    "\n",
    "    # Training configuration\n",
    "initial_lr = 0.01\n",
    "lr_decay_factor = 0.5\n",
    "lr_decay_epoch = 10\n",
    "early_stopping_patience = 3\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "start_time = time.time()  # Start time for training\n",
    "for train_loader, val_loader, test_loader in loaders_per_subregion:\n",
    "    model = DeepMusicModel(N//Q)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val_mse = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Adjust learning rate\n",
    "        if epoch % lr_decay_epoch == 0 and epoch > 0:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] *= lr_decay_factor\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            print(targets.shape,outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrumReconstructionModel(nn.Module):\n",
    "    def __init__(self, Q, N):\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "\n",
    "        Args:\n",
    "        Q (int): The number of segments.\n",
    "        N (int): The total number of points in the full music spectrum.\n",
    "        \"\"\"\n",
    "        super(SpectrumReconstructionModel, self).__init__()\n",
    "        self.Q = Q\n",
    "        self.N = N\n",
    "\n",
    "        # You can add layers here if you want to further process the segments before reconstruction\n",
    "        # For example, a fully connected layer for each segment\n",
    "        # self.fc_layers = nn.ModuleList([nn.Linear(segment_size, segment_size) for _ in range(Q)])\n",
    "    \n",
    "    def forward(self, segments):\n",
    "        \"\"\"\n",
    "        Forward pass for reconstructing the spectrum.\n",
    "\n",
    "        Args:\n",
    "        segments (list of Tensors): Outputs of the trained models, each a segment of the spectrum.\n",
    "\n",
    "        Returns:\n",
    "        Tensor: The reconstructed music spectrum.\n",
    "        \"\"\"\n",
    "        reconstructed_spectrum = torch.zeros(self.N)\n",
    "\n",
    "        segment_length = self.N // self.Q\n",
    "\n",
    "        for q, segment in enumerate(segments):\n",
    "            start_index = q * segment_length\n",
    "            if q < self.Q - 1:\n",
    "                end_index = start_index + segment_length\n",
    "            else:\n",
    "                end_index = self.N\n",
    "\n",
    "            # Optionally, further process each segment\n",
    "            # segment = self.fc_layers[q](segment)\n",
    "\n",
    "            reconstructed_spectrum[start_index:end_index] = segment[:end_index - start_index]\n",
    "\n",
    "        return reconstructed_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_segments = []\n",
    "for model in models:\n",
    "    model.eval()  # Mettre le modèle en mode évaluation\n",
    "    with torch.no_grad():\n",
    "        predicted_segment = model(inputs)\n",
    "        predicted_segments.append(predicted_segment.detach().numpy())  # Convertir en numpy si nécessaire\n",
    "\n",
    "# Utiliser SpectrumReconstructionModel pour la reconstruction\n",
    "reconstruction_model = SpectrumReconstructionModel(Q, N)\n",
    "reconstructed_spectrum = reconstruction_model(predicted_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.1  6.9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "nbSources = 2 # Nombre de sources\n",
    "nbSensors = 9 # Nombre de capteurs\n",
    "nbTimePoints = 100 # Nombre de points temporels\n",
    "signal_noise_ratio = 3 # Rapport signal sur bruit en décibels. Si 'False', cela revient à une absence totale de bruit.\n",
    "theta1 = -7 # Angle entre la perpendiculaire à la ligne de capteurs, et la source 1\n",
    "theta2 = 7 # Angle entre la perpendiculaire à la ligne de capteurs, et la source 2\n",
    "var_ratio = [2] # Liste qui donne le rapport entre la variance du signal 1 et celui des autres sources (ex: [2, 3] signifie que la source 2 a une variance 2 fois plus grande que la source 1, et la source 3 a une variance 3 fois plus grande que la source 1)\n",
    "correlation_List = [0.4] # Liste des corrélations. Il y a une corrélation nécéssaire pour chaque paire distincte de sources différentes: 0 pour 1 source, 1 pour 2 sources, 3 pour 3 sources, 6 pour 4 sources etc...\n",
    "# Ordre de remplisage de la correlation_List: de gauche à droite et ligne par ligne, moitié haut-droite de la matrice uniquement, puis symétrie de ces valeurs pour la moitié bas-gauche\n",
    "perturbation_parameter_sd = 0.01 # Écart-type de la distribution normale qui génère les erreurs de calibration des capteurs\n",
    "\n",
    "thetaList = [theta1, theta2]\n",
    "\n",
    "X = generate_X_matrix(nbSources, nbSensors, nbTimePoints, thetaList, var_ratio, correlation_List, signal_noise_ratio, perturbation_parameter_sd)\n",
    "estimated_angles = music_method(X, nbSensors, nbSources, print_angles=True, draw_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
