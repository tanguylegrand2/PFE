{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Signal_generator.generate_signal import generate_X_matrix\n",
    "from Algorithmes.beamforming import beamforming_method\n",
    "from Signal_generator.generate_signal import generate_A_matrix\n",
    "from Signal_generator.generate_signal import generate_S_matrix\n",
    "from Signal_generator.generate_signal import generate_noise\n",
    "from Signal_generator.generate_signal import generate_R_hat\n",
    "from Signal_generator.generate_signal import generate_R_hat_with_phase\n",
    "from Algorithmes.music import music_method\n",
    "from Algorithmes.music import estimate_angles\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import itertools\n",
    "from torchsummary import summary\n",
    "from numpy.linalg import eigh\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from Algorithmes.music import generate_steering_vector\n",
    "from Plots.draw_plot import plot_single_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbSources = 1 # Nombre de sources  dans l'article ils fixent le nombre de sources à 2\n",
    "nbSensors = 9 # Nombre de capteurs\n",
    "nbTimePoints = 100 # Nombre de points temporels\n",
    "\n",
    "\n",
    "#Pour l'échantillon d'entraînements ils utilisent une observation de chaque combinaison d'angles d'arrivée possible pour chaque SNR level, dans le cas d'une seule source, 2G+1 observations\n",
    "#SNR ratio dans le papier est seulement low, de -20 à 0 DB avec un pas de 5\n",
    "#Petite note : si on fait un modèle pour chaque SNR level, les performances augmentent légérements, mais cela ne vaut pas l'effort effectué\n",
    "signal_noise_ratio = 3 # Rapport signal sur bruit en décibels. Si 'False', cela revient à une absence totale de bruit.\n",
    "L = nbSensors\n",
    "T = 400\n",
    "correlation_List = [] # Liste des corrélations. Il y a une corrélation nécéssaire pour chaque paire distincte de sources différentes: 0 pour 1 source, 1 pour 2 sources, 3 pour 3 sources, 6 pour 4 sources etc...\n",
    "# Ordre de remplisage de la correlation_List: de gauche à droite et ligne par ligne, moitié haut-droite de la matrice uniquement, puis symétrie de ces valeurs pour la moitié bas-gauche.\n",
    "SNR_TRAIN = 30\n",
    "Q = 8\n",
    "N = 2**12 \n",
    "theta_start = -45\n",
    "theta_final = 45\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_music_spectrum(R_hat, nbSensors, nbSources, theta_range):\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(R_hat)\n",
    "    noise_subspace = eigenvectors[:, :nbSensors - nbSources]\n",
    "    music_spectrum = np.zeros(len(theta_range))\n",
    "\n",
    "    for i, theta in enumerate(theta_range):\n",
    "        steering_vector = generate_steering_vector(nbSensors, theta)\n",
    "        music_spectrum[i] = 1 / np.abs(np.conj(steering_vector).T @ noise_subspace @ noise_subspace.conj().T @ steering_vector)\n",
    "\n",
    "    return music_spectrum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "def generate_deepmusic_partitioned_data(nbSensors, nbSources, T, J_alpha, J_beta, SNR_TRAIN, Q, N, theta_start, theta_final):\n",
    "    training_data_sets = [[] for _ in range(Q)]\n",
    "\n",
    "    for j_alpha in range(J_alpha):\n",
    "        thetaList = np.random.uniform(theta_start, theta_final, nbSources).tolist()\n",
    "\n",
    "        for j_beta in range(J_beta):\n",
    "            varList = np.ones(nbSources).tolist()\n",
    "            correlation_List = np.zeros(nbSources * (nbSources - 1) // 2).tolist()\n",
    "            X = generate_X_matrix(nbSources, nbSensors, T, thetaList, varList, correlation_List, SNR_TRAIN)\n",
    "            \n",
    "            R_hat = generate_R_hat(X)\n",
    "            full_theta = np.linspace(theta_start, theta_final, N)\n",
    "            full_music_spectrum = calculate_music_spectrum(R_hat, nbSensors, nbSources, full_theta)\n",
    "\n",
    "            for q in range(Q):\n",
    "                # Sampling MUSIC spectrum for the q-th subregion\n",
    "                start_index = q * L\n",
    "                end_index = start_index + L\n",
    "                pq = full_music_spectrum[start_index:end_index]\n",
    "                \n",
    "                input_data = generate_R_hat_with_phase(X)\n",
    "                output_data = pq\n",
    "                training_data_sets[q].append((input_data, output_data))                \n",
    "\n",
    "    return training_data_sets\n",
    "\n",
    "# Example usage\n",
    "J_alpha = 100  # Number of DOA angle sets to generate\n",
    "J_beta = 10   # Number of iterations for each set of DOA angles\n",
    "SNR_TRAIN_list = [15,20, 25, 30] # Different SNR levels for training\n",
    "theta_range = np.linspace(theta_start, theta_final, N*Q)\n",
    "training_datasets = generate_deepmusic_partitioned_data(nbSensors, nbSources, T, J_alpha, J_beta, SNR_TRAIN, Q, N,theta_start, theta_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class DeepMusicDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_data, output_data = self.data[idx]\n",
    "        return torch.tensor(input_data, dtype=torch.float32), torch.tensor(output_data, dtype=torch.float32)\n",
    "\n",
    "def create_loaders_for_all_subregions(Q, training_datasets, batch_size=128, validation_split=0.2, test_split=0.2):\n",
    "    train_loaders = []\n",
    "    val_loaders = []\n",
    "    test_loaders = []\n",
    "\n",
    "    for q in range(Q):\n",
    "        train_data, test_data = train_test_split(training_datasets[q], test_size=test_split, random_state=42)\n",
    "        train_data, val_data = train_test_split(train_data, test_size=validation_split, random_state=42)\n",
    "\n",
    "        train_dataset = DeepMusicDataset(train_data)\n",
    "        val_dataset = DeepMusicDataset(val_data)\n",
    "        test_dataset = DeepMusicDataset(test_data)\n",
    "\n",
    "        train_loaders.append(DataLoader(train_dataset, batch_size=batch_size, shuffle=True))\n",
    "        val_loaders.append(DataLoader(val_dataset, batch_size=batch_size, shuffle=False))\n",
    "        test_loaders.append(DataLoader(test_dataset, batch_size=batch_size, shuffle=False))\n",
    "\n",
    "    return train_loaders, val_loaders, test_loaders\n",
    "\n",
    "# Utilisation de la fonction\n",
    "train_loaders, val_loaders, test_loaders = create_loaders_for_all_subregions(Q, training_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DeepMusicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepMusicModel, self).__init__()\n",
    "        # Define the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the fourth convolutional layer\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Assuming the spatial dimensions (height and width) are reduced to 1x1 after the convolutions\n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=20736, out_features=9)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Softmax layer \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the first convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # Apply the second convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        \n",
    "        # Apply the third convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Apply the fourth convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        # Flatten the tensor for the fully connected layer\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Apply the first fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        # Apply the dropout layer\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #Apply the softmax layer\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MultipleDeepMusicModels(nn.Module):\n",
    "    def __init__(self, q):\n",
    "        super(MultipleDeepMusicModels, self).__init__()\n",
    "        self.models = nn.ModuleList([DeepMusicModel() for _ in range(q)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Générer les sorties pour chaque modèle et chaque élément de x\n",
    "        outputs = [model(x_elem) for model, x_elem in zip(self.models, x)]\n",
    "\n",
    "        # Concaténer toutes les sorties en une seule\n",
    "        concatenated_outputs = torch.cat(outputs, dim=1)  # Ajustez la dimension selon la structure de vos données\n",
    "        return concatenated_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DeepMusicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepMusicModel, self).__init__()\n",
    "        # Define the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the fourth convolutional layer\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Assuming the spatial dimensions (height and width) are reduced to 1x1 after the convolutions\n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=20736, out_features=9)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        # Softmax layer \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the first convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # Apply the second convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        \n",
    "        # Apply the third convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Apply the fourth convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        # Flatten the tensor for the fully connected layer\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Apply the first fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        # Apply the dropout layer\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #Apply the softmax layer\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MultipleDeepMusicModels(nn.Module):\n",
    "    def __init__(self, q):\n",
    "        super(MultipleDeepMusicModels, self).__init__()\n",
    "        self.models = nn.ModuleList([DeepMusicModel() for _ in range(q)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [model(x_elem) for model, x_elem in zip(self.models, x)]\n",
    "        return outputs\n",
    "\n",
    "model = MultipleDeepMusicModels(Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#Définition du device\n",
    "\n",
    "device = (\n",
    "    \"gpu\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [256, 3, 5, 5], expected input[1, 24, 9, 9] to have 3 channels, but got 24 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 78\u001b[0m\n\u001b[0;32m     76\u001b[0m theta_range \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(theta_start, theta_final, N\u001b[38;5;241m*\u001b[39mQ)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m \u001b[43mtrain_and_evaluate_spectrum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbSources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 21\u001b[0m, in \u001b[0;36mtrain_and_evaluate_spectrum\u001b[1;34m(train_loaders, val_loaders, test_loaders, epochs, nbSources, angles_range, peak_tolerance)\u001b[0m\n\u001b[0;32m     19\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([data[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m batch_per_subregion], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 63\u001b[0m, in \u001b[0;36mMultipleDeepMusicModels.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 63\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_elem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_elem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "Cell \u001b[1;32mIn[26], line 63\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 63\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_elem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m model, x_elem \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels, x)]\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 32\u001b[0m, in \u001b[0;36mDeepMusicModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Apply the first convolutional layer and normalization, followed by ReLU\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Apply the second convolutional layer and normalization, followed by ReLU\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [256, 3, 5, 5], expected input[1, 24, 9, 9] to have 3 channels, but got 24 channels instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def train_and_evaluate_spectrum(train_loaders, val_loaders, test_loaders, epochs, nbSources, angles_range, peak_tolerance=5):\n",
    "    Q = len(train_loaders)\n",
    "    multi_model = MultipleDeepMusicModels(Q)\n",
    "    optimizer = torch.optim.SGD(multi_model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "    no_improve_epoch = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training loop\n",
    "        multi_model.train()\n",
    "        for batch_per_subregion in zip(*train_loaders):\n",
    "            inputs = torch.cat([data[0] for data in batch_per_subregion], dim=1)\n",
    "            targets = torch.cat([data[1] for data in batch_per_subregion], dim=1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = multi_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        multi_model.eval()\n",
    "        val_loss = 0\n",
    "        val_accuracies = []\n",
    "        with torch.no_grad():\n",
    "            for batch_per_subregion in zip(*val_loaders):\n",
    "                inputs = torch.cat([data[0] for data in batch_per_subregion], dim=1)\n",
    "                targets = torch.cat([data[1] for data in batch_per_subregion], dim=1)\n",
    "                outputs = multi_model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item()\n",
    "                val_accuracies.append(calculate_accuracy(outputs, targets, angles_range, nbSources, peak_tolerance))\n",
    "\n",
    "        avg_val_accuracy = np.mean(val_accuracies)\n",
    "        if avg_val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = avg_val_accuracy\n",
    "            no_improve_epoch = 0\n",
    "        else:\n",
    "            no_improve_epoch += 1\n",
    "            if no_improve_epoch >= 3:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Learning rate decay\n",
    "        if epoch % 10 == 9:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] *= 0.5\n",
    "\n",
    "        print(f'Epoch {epoch}: Avg Val Loss {val_loss / len(val_loaders[0])}, Avg Val Accuracy {avg_val_accuracy}')\n",
    "\n",
    "    # Test evaluation\n",
    "    total_mse = 0\n",
    "    total_angle_accuracy = 0\n",
    "    test_batches = 0\n",
    "    multi_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs_per_subregion in zip(*test_loaders):\n",
    "            inputs = [data[0] for data in inputs_per_subregion]\n",
    "            targets = torch.cat([data[1] for data in inputs_per_subregion], dim=1)\n",
    "            outputs = multi_model(inputs)\n",
    "            total_mse += F.mse_loss(outputs, targets).item()\n",
    "            total_angle_accuracy += calculate_accuracy(outputs, targets, angles_range, nbSources, peak_tolerance)\n",
    "            test_batches += 1\n",
    "\n",
    "    avg_test_mse = total_mse / test_batches\n",
    "    avg_test_angle_accuracy = total_angle_accuracy / test_batches\n",
    "    print(f'Average MSE on Test Set: {avg_test_mse:.4f}')\n",
    "    print(f'Average Angle Accuracy on Test Set: {avg_test_angle_accuracy:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "theta_range = np.linspace(theta_start, theta_final, N*Q)\n",
    "# Example usage\n",
    "train_and_evaluate_spectrum(train_loaders, val_loaders, test_loaders, 5, nbSources, theta_range, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
