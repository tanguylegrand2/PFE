{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Signal_generator.generate_signal import generate_X_matrix\n",
    "from Algorithmes.beamforming import beamforming_method\n",
    "from Signal_generator.generate_signal import generate_A_matrix\n",
    "from Signal_generator.generate_signal import generate_noise\n",
    "from Signal_generator.generate_signal import generate_R_hat\n",
    "from Signal_generator.generate_signal import generate_R_hat_with_phase\n",
    "from Algorithmes.music import music_method\n",
    "from Algorithmes.music import estimate_angles\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import itertools\n",
    "from torchsummary import summary\n",
    "from numpy.linalg import eigh\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbSources = 1 # Nombre de sources  dans l'article ils fixent le nombre de sources à 2\n",
    "nbSensors = 9 # Nombre de capteurs\n",
    "nbTimePoints = 100 # Nombre de points temporels\n",
    "\n",
    "\n",
    "\n",
    "#Pour l'échantillon d'entraînements ils utilisent une observation de chaque combinaison d'angles d'arrivée possible pour chaque SNR level, dans le cas d'une seule source, 2G+1 observations\n",
    "#SNR ratio dans le papier est seulement low, de -20 à 0 DB avec un pas de 5\n",
    "#Petite note : si on fait un modèle pour chaque SNR level, les performances augmentent légérements, mais cela ne vaut pas l'effort effectué\n",
    "signal_noise_ratio = 3 # Rapport signal sur bruit en décibels. Si 'False', cela revient à une absence totale de bruit.\n",
    "L = nbSensors\n",
    "T = 100\n",
    "correlation_List = [] # Liste des corrélations. Il y a une corrélation nécéssaire pour chaque paire distincte de sources différentes: 0 pour 1 source, 1 pour 2 sources, 3 pour 3 sources, 6 pour 4 sources etc...\n",
    "# Ordre de remplisage de la correlation_List: de gauche à droite et ligne par ligne, moitié haut-droite de la matrice uniquement, puis symétrie de ces valeurs pour la moitié bas-gauche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Paramètres pour la simulation\n",
    "\n",
    "num_samples = 1000  # Nombre d'échantillons à générer #16290\n",
    "L = nbSensors  # Nombre de capteurs\n",
    "T = 100  # Nombre de points temporels\n",
    "phi_max = 45  # φmax\n",
    "rho = 1 # Résolution\n",
    "\n",
    "# Grille des angles\n",
    "G = np.arange(-phi_max, phi_max + rho, rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1158272649.py, line 91)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[34], line 91\u001b[1;36m\u001b[0m\n\u001b[1;33m    all_R_hat_with_phase, all_music_spectra=generation_donnees(phi_max, rho, [15; 20; 25; 30],[],[])\u001b[0m\n\u001b[1;37m                                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import eigh\n",
    "\n",
    "def generate_combinations(phi_max, rho, nb_sources):\n",
    "    \"\"\"Cette fonction sert à générer toutes les combinaisons d'angles possibles dans la plage de résolution\"\"\"\n",
    "    # Générer une plage de valeurs possibles pour les signaux\n",
    "    values = list(range(-int(phi_max / rho), int(phi_max / rho) + 1))\n",
    "    \n",
    "    # Générer toutes les combinaisons possibles de signaux\n",
    "    all_combinations = list(itertools.product(values, repeat=nb_sources))\n",
    "    \n",
    "    # Supprimer les combinaisons où l'ordre ne compte pas\n",
    "    unique_combinations = set()\n",
    "    for combination in all_combinations:\n",
    "        sorted_combination = tuple(sorted(combination))\n",
    "        unique_combinations.add(sorted_combination)\n",
    "    unique_combinations=list(unique_combinations)\n",
    "        \n",
    "    #supprimer les combinaisons ou deux signaux ont la même valeur\n",
    "    combination_a_supp=[]\n",
    "    for combination in unique_combinations:\n",
    "        presents=[]\n",
    "        for element in combination:\n",
    "            if element not in presents:\n",
    "                presents.append(element)\n",
    "            else:\n",
    "                combination_a_supp.append(combination)\n",
    "    for combination in combination_a_supp:\n",
    "        unique_combinations.remove(combination)\n",
    "                \n",
    "        \n",
    "    \n",
    "    return unique_combinations\n",
    "\n",
    "def generate_music_spectrum(R, L, G, d=0.5, fs=1):\n",
    "    \"\"\"\n",
    "    Calcule le spectre MUSIC à partir de la matrice de covariance R.\n",
    "\n",
    "    :param R: Matrice de covariance estimée.\n",
    "    :param L: Nombre de capteurs.\n",
    "    :param G: Grille des angles (en degrés).\n",
    "    :param d: Distance entre les éléments du réseau de capteurs (en longueurs d'onde).\n",
    "    :param fs: Fréquence d'échantillonnage.\n",
    "    :return: Spectre MUSIC pour les angles dans G.\n",
    "    \"\"\"\n",
    "    # Calcul des valeurs propres et vecteurs propres\n",
    "    eigvals, eigvecs = eigh(R)\n",
    "    \n",
    "    # Séparation des vecteurs du signal et du bruit\n",
    "    E_noise = eigvecs[:, :L-2]  # Supposant 2 sources max\n",
    "    \n",
    "    # Calcul du spectre MUSIC\n",
    "    P_music = np.zeros(len(G))\n",
    "    for i, theta in enumerate(G):\n",
    "        a = np.exp(np.arange(L) * 1j * 2 * np.pi * d * np.sin(np.radians(theta)) / fs)\n",
    "        P_music[i] = 1 / np.abs(a.conj().T @ E_noise @ E_noise.conj().T @ a)\n",
    "    \n",
    "    # Normalisation du spectre\n",
    "    P_music = P_music / np.max(P_music)\n",
    "    \n",
    "    return P_music\n",
    "\n",
    "def generation_donnees( phi_max : int, rho : float, SNR : list, correlation : list, calibration ):\n",
    "    angles_combination=generate_combinations(phi_max,rho,nbSources)\n",
    "    num_samples=len(angles_combination)*len(SNR)\n",
    "    \n",
    "    # Initialisation des tableaux pour les données\n",
    "    all_R_hat_with_phase = np.zeros((num_samples, 3, L, L))\n",
    "    all_music_spectra = np.zeros((num_samples, len(G)))\n",
    "    \n",
    "    #On parcourt les différents SNR possibles\n",
    "    i=0\n",
    "    for snr in SNR:\n",
    "        # Générer les angles d'arrivée et la matrice X comme décrit précédemment\n",
    "        for angles in angles_combination:\n",
    "            thetaList=list(angles)\n",
    "            varList = [np.random.uniform(0, 1000000000000) for _ in range(nbSources)]\n",
    "            X = generate_X_matrix(nbSources, L, T, thetaList, varList, correlation_List, snr)# Votre fonction pour générer X, ajoutez les paramètres nécessaires\n",
    "            \n",
    "            # Calculer R_hat étendue avec phase\n",
    "            R_hat_with_phase = generate_R_hat_with_phase(X)\n",
    "            all_R_hat_with_phase[i] = R_hat_with_phase\n",
    "            \n",
    "            # Calculer les labels Z pour les angles générés\n",
    "            R = all_R_hat_with_phase[i, :, :, 0] + 1j * all_R_hat_with_phase[i, :, :, 1]  # Reconstitution de la matrice complexe\n",
    "            all_music_spectra[i] = music_method(X, nbSensors, nbSources)\n",
    "            i+=1\n",
    "    return all_R_hat_with_phase, all_music_spectra\n",
    "\n",
    "# Initialisation des tableaux pour les données\n",
    "all_R_hat_with_phase, all_music_spectra=generation_donnees(phi_max, rho, [15, 20, 25, 30],[],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.25616348e+11]]\n",
      "[[9.4693619e+11]]\n",
      "[[4.06655901e+11]]\n",
      "[[9.16059299e+11]]\n",
      "[[9.48813018e+11]]\n",
      "[[3.2587842e+11]]\n",
      "[[3.04540354e+11]]\n",
      "[[9.31078352e+11]]\n",
      "[[4.81744429e+11]]\n",
      "[[7.43877855e+11]]\n",
      "[[4.53716184e+11]]\n",
      "[[2.58425699e+11]]\n",
      "[[3.80674768e+11]]\n",
      "[[4.84969271e+11]]\n",
      "[[8.91864015e+10]]\n",
      "[[4.59168303e+11]]\n",
      "[[4.76718848e+11]]\n",
      "[[5.40509174e+11]]\n",
      "[[2.8818426e+11]]\n",
      "[[9.75727696e+11]]\n",
      "[[9.95806499e+11]]\n",
      "[[2.51243387e+11]]\n",
      "[[1.08715859e+11]]\n",
      "[[3.82566098e+11]]\n",
      "[[2.55551555e+11]]\n",
      "[[7.63600303e+11]]\n",
      "[[7.58568107e+11]]\n",
      "[[7.43623382e+11]]\n",
      "[[4.63773825e+11]]\n",
      "[[5.90551974e+11]]\n",
      "[[9.77957811e+11]]\n",
      "[[9.09166727e+11]]\n",
      "[[7.84227833e+11]]\n",
      "[[5.90234121e+11]]\n",
      "[[3.21676068e+11]]\n",
      "[[7.13284828e+11]]\n",
      "[[8.83647018e+11]]\n",
      "[[5.96758842e+11]]\n",
      "[[2.27839144e+10]]\n",
      "[[3.84296909e+10]]\n",
      "[[5.35441947e+11]]\n",
      "[[2.41143823e+11]]\n",
      "[[1.12495792e+11]]\n",
      "[[7.54319203e+10]]\n",
      "[[2.51829959e+11]]\n",
      "[[1.4499185e+11]]\n",
      "[[3.31019356e+11]]\n",
      "[[9.20417958e+11]]\n",
      "[[3.75630515e+11]]\n",
      "[[1.07020687e+11]]\n",
      "[[4.52060436e+11]]\n",
      "[[9.84101351e+11]]\n",
      "[[3.03721072e+11]]\n",
      "[[8.98403428e+11]]\n",
      "[[6.22884783e+11]]\n",
      "[[78917265.42497146]]\n",
      "[[3.72512531e+10]]\n",
      "[[7.13885542e+11]]\n",
      "[[3.33529979e+11]]\n",
      "[[7.83241363e+11]]\n",
      "[[5.04700151e+11]]\n",
      "[[7.98413848e+11]]\n",
      "[[9.3412269e+11]]\n",
      "[[4.48540996e+11]]\n",
      "[[7.30273523e+11]]\n",
      "[[8.93337755e+11]]\n",
      "[[6.57757374e+11]]\n",
      "[[2.39592625e+11]]\n",
      "[[1.14583424e+11]]\n",
      "[[5.6899444e+11]]\n",
      "[[6.42482487e+11]]\n",
      "[[8.19555829e+11]]\n",
      "[[9.28748135e+11]]\n",
      "[[8.12167025e+11]]\n",
      "[[5.90814506e+09]]\n",
      "[[3.36122357e+11]]\n",
      "[[6.34624309e+11]]\n",
      "[[8.14702306e+11]]\n",
      "[[7.16105427e+11]]\n",
      "[[7.2820803e+11]]\n",
      "[[1.47012027e+11]]\n",
      "[[4.90183682e+11]]\n",
      "[[2.95650267e+11]]\n",
      "[[7.24413745e+11]]\n",
      "[[1.63769414e+11]]\n",
      "[[2.71414414e+11]]\n",
      "[[8.6508119e+11]]\n",
      "[[4.91502252e+11]]\n",
      "[[7.02142257e+11]]\n",
      "[[4.83553211e+11]]\n",
      "[[4.59617102e+11]]\n",
      "[[2.00899415e+10]]\n",
      "[[1.20178463e+10]]\n",
      "[[9.23612083e+11]]\n",
      "[[5.52364167e+11]]\n",
      "[[3.27442476e+11]]\n",
      "[[1.69309922e+11]]\n",
      "[[9.18706401e+11]]\n",
      "[[3.683279e+10]]\n",
      "[[2.88406731e+11]]\n",
      "[[4.46940481e+11]]\n",
      "[[2.52694367e+11]]\n",
      "[[5.51644816e+11]]\n",
      "[[3.21464399e+11]]\n",
      "[[8.84983511e+11]]\n",
      "[[2.29207879e+11]]\n",
      "[[2.59397494e+10]]\n",
      "[[9.49301167e+11]]\n",
      "[[2.75301909e+11]]\n",
      "[[6.35425602e+11]]\n",
      "[[8.2410451e+11]]\n",
      "[[8.38741199e+11]]\n",
      "[[1.22471049e+11]]\n",
      "[[6.39022501e+11]]\n",
      "[[9.57050403e+11]]\n",
      "[[7.30949895e+11]]\n",
      "[[1.40275905e+11]]\n",
      "[[5.02540749e+11]]\n",
      "[[2.59235425e+11]]\n",
      "[[8.82704186e+11]]\n",
      "[[5.84715011e+11]]\n",
      "[[3.67627825e+11]]\n",
      "[[5.59145203e+11]]\n",
      "[[3.16834271e+11]]\n",
      "[[8.99466982e+11]]\n",
      "[[3.55502024e+11]]\n",
      "[[7.00432529e+11]]\n",
      "[[7.56340941e+11]]\n",
      "[[6.13117981e+11]]\n",
      "[[3.87456894e+11]]\n",
      "[[4.42489311e+10]]\n",
      "[[8.40493539e+11]]\n",
      "[[2.27542647e+11]]\n",
      "[[6.67336487e+11]]\n",
      "[[8.73381544e+11]]\n",
      "[[7.83213398e+11]]\n",
      "[[2.53688959e+11]]\n",
      "[[1.64851405e+11]]\n",
      "[[9.78258624e+11]]\n",
      "[[4.99352953e+11]]\n",
      "[[2.31780585e+11]]\n",
      "[[1.9998744e+11]]\n",
      "[[3.3547679e+11]]\n",
      "[[1.99151614e+11]]\n",
      "[[8.03429718e+11]]\n",
      "[[2.08471093e+10]]\n",
      "[[2.59282305e+11]]\n",
      "[[2.45752886e+11]]\n",
      "[[1.46649747e+11]]\n",
      "[[7.25647875e+11]]\n",
      "[[2.7272885e+11]]\n",
      "[[9.265894e+11]]\n",
      "[[6.20317588e+11]]\n",
      "[[8.62045546e+11]]\n",
      "[[1.83125954e+11]]\n",
      "[[9.34215438e+11]]\n",
      "[[6.66661984e+11]]\n",
      "[[5.49596926e+11]]\n",
      "[[1.12271172e+11]]\n",
      "[[7.36744913e+11]]\n",
      "[[1.53355028e+11]]\n",
      "[[3.56602152e+11]]\n",
      "[[1.08735772e+10]]\n",
      "[[4.95930613e+11]]\n",
      "[[7.15305492e+10]]\n",
      "[[6.03945852e+11]]\n",
      "[[4.00616149e+11]]\n",
      "[[6.02762443e+11]]\n",
      "[[9.2639321e+11]]\n",
      "[[1.32106603e+11]]\n",
      "[[3.00688562e+11]]\n",
      "[[8.2102673e+11]]\n",
      "[[9.65025876e+11]]\n",
      "[[4.67233075e+11]]\n",
      "[[1.13514198e+10]]\n",
      "[[4.90465605e+10]]\n",
      "[[2.99269238e+11]]\n",
      "[[3.21872706e+11]]\n",
      "[[6.75668533e+11]]\n",
      "[[7.20695376e+11]]\n",
      "[[8.83702937e+11]]\n",
      "[[7.7395964e+11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import eigh\n",
    "\n",
    "def generate_combinations(phi_max, rho, nb_sources):\n",
    "    \"\"\"Cette fonction sert à générer toutes les combinaisons d'angles possibles dans la plage de résolution\"\"\"\n",
    "    # Générer une plage de valeurs possibles pour les signaux\n",
    "    values = list(range(-int(phi_max / rho), int(phi_max / rho) + 1))\n",
    "    \n",
    "    # Générer toutes les combinaisons possibles de signaux\n",
    "    all_combinations = list(itertools.product(values, repeat=nb_sources))\n",
    "    \n",
    "    # Supprimer les combinaisons où l'ordre ne compte pas\n",
    "    unique_combinations = set()\n",
    "    for combination in all_combinations:\n",
    "        sorted_combination = tuple(sorted(combination))\n",
    "        unique_combinations.add(sorted_combination)\n",
    "    unique_combinations=list(unique_combinations)\n",
    "        \n",
    "    #supprimer les combinaisons ou deux signaux ont la même valeur\n",
    "    combination_a_supp=[]\n",
    "    for combination in unique_combinations:\n",
    "        presents=[]\n",
    "        for element in combination:\n",
    "            if element not in presents:\n",
    "                presents.append(element)\n",
    "            else:\n",
    "                combination_a_supp.append(combination)\n",
    "    for combination in combination_a_supp:\n",
    "        unique_combinations.remove(combination)\n",
    "                \n",
    "        \n",
    "    \n",
    "    return unique_combinations\n",
    "\n",
    "def generate_music_spectrum(R, L, G, d=0.5, fs=1):\n",
    "    \"\"\"\n",
    "    Calcule le spectre MUSIC à partir de la matrice de covariance R.\n",
    "\n",
    "    :param R: Matrice de covariance estimée.\n",
    "    :param L: Nombre de capteurs.\n",
    "    :param G: Grille des angles (en degrés).\n",
    "    :param d: Distance entre les éléments du réseau de capteurs (en longueurs d'onde).\n",
    "    :param fs: Fréquence d'échantillonnage.\n",
    "    :return: Spectre MUSIC pour les angles dans G.\n",
    "    \"\"\"\n",
    "    # Calcul des valeurs propres et vecteurs propres\n",
    "    eigvals, eigvecs = eigh(R)\n",
    "    \n",
    "    # Séparation des vecteurs du signal et du bruit\n",
    "    E_noise = eigvecs[:, :L-2]  # Supposant 2 sources max\n",
    "    \n",
    "    # Calcul du spectre MUSIC\n",
    "    P_music = np.zeros(len(G))\n",
    "    for i, theta in enumerate(G):\n",
    "        a = np.exp(np.arange(L) * 1j * 2 * np.pi * d * np.sin(np.radians(theta)) / fs)\n",
    "        P_music[i] = 1 / np.abs(a.conj().T @ E_noise @ E_noise.conj().T @ a)\n",
    "    \n",
    "    # Normalisation du spectre\n",
    "    P_music = P_music / np.max(P_music)\n",
    "    \n",
    "    return P_music\n",
    "\n",
    "def generation_donnees( phi_max : int, rho : float, SNR : list, correlation : list, calibration ):\n",
    "    angles_combination=generate_combinations(phi_max,rho,nbSources)\n",
    "    num_samples=len(angles_combination)*len(SNR)\n",
    "    \n",
    "    # Initialisation des tableaux pour les données\n",
    "    all_R_hat_with_phase = np.zeros((num_samples, 3, L, L))\n",
    "    all_music_spectra = np.zeros((num_samples, len(G)))\n",
    "    \n",
    "    #On parcourt les différents SNR possibles\n",
    "    i=0\n",
    "    for snr in SNR:\n",
    "        # Générer les angles d'arrivée et la matrice X comme décrit précédemment\n",
    "        for angles in angles_combination:\n",
    "            thetaList=list(angles)\n",
    "            varList = [np.random.uniform(0, 1000000000000) for _ in range(nbSources)]\n",
    "            X = generate_X_matrix(nbSources, L, T, thetaList, varList, correlation_List, snr)# Votre fonction pour générer X, ajoutez les paramètres nécessaires\n",
    "            \n",
    "            # Calculer R_hat étendue avec phase\n",
    "            R_hat_with_phase = generate_R_hat_with_phase(X)\n",
    "            all_R_hat_with_phase[i] = R_hat_with_phase\n",
    "            \n",
    "            # Calculer les labels Z pour les angles générés\n",
    "            R = all_R_hat_with_phase[i, :, :, 0] + 1j * all_R_hat_with_phase[i, :, :, 1]  # Reconstitution de la matrice complexe\n",
    "            all_music_spectra[i] = music_method(X, nbSensors, nbSources)\n",
    "            i+=1\n",
    "    return all_R_hat_with_phase, all_music_spectra\n",
    "\n",
    "# Initialisation des tableaux pour les données\n",
    "all_R_hat_with_phase, all_music_spectra=generation_donnees(phi_max, rho, [0,-5],[],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(all_R_hat_with_phase, all_music_spectra, test_size=0.1 , random_state=42)#test_size=0.1 selon papier\n",
    "X_train, X_val, Y_train, Y_val= train_test_split(X_train, Y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DOADataset(Dataset):\n",
    "    def __init__(self, covariance_matrices, spectra):\n",
    "        \"\"\"\n",
    "        Initialisation du Dataset DOA.\n",
    "\n",
    "        Args:\n",
    "        - covariance_matrices (np.ndarray): Matrices de covariance étendues avec la phase.\n",
    "          Forme attendue: (nb_samples, nbSensors, nbSensors, 3) pour les parties réelle, imaginaire, et la phase.\n",
    "        - spectra (np.ndarray): Spectres MUSIC sous forme de vecteurs.\n",
    "          Forme attendue: (nb_samples, len(G)), où len(G) est le nombre de points dans la grille DOA.\n",
    "        \"\"\"\n",
    "        self.covariance_matrices = covariance_matrices\n",
    "        self.spectra = spectra\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.covariance_matrices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cov_matrix = self.covariance_matrices[idx]\n",
    "        spectrum = self.spectra[idx]\n",
    "\n",
    "        # Conversion en tenseur PyTorch\n",
    "        cov_matrix = torch.tensor(cov_matrix, dtype=torch.float32)\n",
    "        spectrum = torch.tensor(spectrum, dtype=torch.float32)\n",
    "\n",
    "        return cov_matrix, spectrum\n",
    "\n",
    "# Utilisation avec vos données X_train et Y_train\n",
    "train_dataset = DOADataset(X_train, Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Utilisation avec vos données X_val et Y_val pour l'ensemble de validation\n",
    "val_dataset = DOADataset(X_val, Y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)  # Pas besoin de shuffle pour l'ensemble de validation\n",
    "\n",
    "# Utilisation avec vos données X_test et Y_test pour l'ensemble de test\n",
    "test_dataset = DOADataset(X_test, Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DeepMusicModel(nn.Module):\n",
    "    def __init__(self, num_classes=91):\n",
    "        super(DeepMusicModel, self).__init__()\n",
    "\n",
    "        # Couches convolutionnelles\n",
    "        self.fc1 = nn.Linear(in_features=9*9*3, out_features=251)\n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5)\n",
    "        self.conv8 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5)\n",
    "        self.conv11 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5)\n",
    "\n",
    "        # Couches d'activation ReLU\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.relu8 = nn.ReLU()\n",
    "        self.relu11 = nn.ReLU()\n",
    "\n",
    "        # Couches de normalisation\n",
    "        self.norm3 = nn.BatchNorm2d(256)\n",
    "        self.norm6 = nn.BatchNorm2d(256)\n",
    "        self.norm9 = nn.BatchNorm2d(256)\n",
    "        self.norm12 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Couche de convolution (kernel 1x1)\n",
    "        self.conv15 = nn.Conv2d(256, 256, kernel_size=1)\n",
    "\n",
    "        # Couche de dropout\n",
    "        self.dropout16 = nn.Dropout(0.5)\n",
    "\n",
    "        # Couches entièrement connectées (FC)\n",
    "        self.fc17 = nn.Linear(in_features=7680, out_features=num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x) \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.norm4(x)\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.norm7(x)\n",
    "        \n",
    "        x = self.conv8(x)\n",
    "        x = self.relu9(x)\n",
    "        x = self.norm10(x)\n",
    "        \n",
    "        x = self.conv11(x)\n",
    "        x = self.relu12(x)\n",
    "        x = self.norm13(x)\n",
    "        \n",
    "        x = self.conv14(x)\n",
    "                \n",
    "        x = self.dropout16(x)\n",
    "        x = x.view(x.size(0), -1)  # Aplatir pour FC\n",
    "        x = self.fc17(x)\n",
    "        \n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Création de l'instance du modèle\n",
    "model = DeepMusicModel()\n",
    "\n",
    "# Définition de l'optimiseur et de la fonction de perte\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DeepMusicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepMusicModel, self).__init__()\n",
    "        # Define the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Define the fourth convolutional layer\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=256)\n",
    "        \n",
    "        # Assuming the spatial dimensions (height and width) are reduced to 1x1 after the convolutions\n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features=20736, out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=91)  # Example output size\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # Softmax is typically applied in the last layer if this is for classification\n",
    "        # For regression or other tasks, it may not be necessary\n",
    "        # self.softmax = nn.Softmax(dim=1)  # Uncomment if needed for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the first convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # Apply the second convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        \n",
    "        # Apply the third convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Apply the fourth convolutional layer and normalization, followed by ReLU\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        # Flatten the tensor for the fully connected layer\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Apply the first fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # Apply the dropout layer\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply the second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Apply softmax if this is for classification\n",
    "        # x = self.softmax(x)  # Uncomment if needed for classification\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create the CNN model\n",
    "model = DeepMusicModel()\n",
    "\n",
    "# Définition de l'optimiseur et de la fonction de perte\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:35\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def initialize_cnns(num_subregions=10, input_size=91):\n",
    "    cnns = [DeepMusicModel() for _ in range(num_subregions)]\n",
    "    return cnns\n",
    "\n",
    "# Example training loop for one CNN (extend this for training multiple CNNs)\n",
    "def train_cnn(model, train_loader, epochs=100):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for data, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "#Boucle d'entraînement\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    for data, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "#Boucle de tests\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct, MSE = 0, 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            _, angles_predit = pred.topk(nbSources, dim=1)\n",
    "            _,angles_correct=top_values, top_indices = y.topk(nbSources, dim=1)\n",
    "            correct += (angles_predit==angles_correct).type(torch.float).sum().item()\n",
    "            #Calcul de la somme des carrés des différences entre prédictions et réalité pour la RMSE\n",
    "            for angle in range(nbSources):\n",
    "                MSE+=(angles_correct[angle]-angles_predit[angle])**2\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    RMSE=math.sqrt(MSE/(len(test_dataloader)*nbSources))\n",
    "    print(f\"\\nTest set: \\n  Accuracy: {(100 * correct): >0.1f}%, Avg loss: {test_loss: >8f} \\n RMSE : {RMSE: >8f}\")\n",
    "    return test_loss, correct\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device):\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        test_loop(test_dataloader, model, loss_fn, device)\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#Définition du device\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définition des hyperparamètres, choisis en fonction de l'article DOA estimator\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10 # à monter à 200 pour le training final selon l'article\n",
    "loss_fn = nn.BCELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subregions = 8\n",
    "cnns = initialize_cnns(num_subregions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of target should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cnn \u001b[38;5;129;01min\u001b[39;00m cnns:\n\u001b[0;32m      3\u001b[0m      \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i))\n\u001b[1;32m----> 4\u001b[0m      \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m      i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[52], line 82\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     test_loop(test_dataloader, model, loss_fn, device)\n\u001b[0;32m     84\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[52], line 34\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Compute prediction and loss\u001b[39;00m\n\u001b[0;32m     33\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[1;32m---> 34\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m     37\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:3122\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3119\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3120\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: all elements of target should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for cnn in cnns:\n",
    "     print(\"Model {}\".format(i))\n",
    "     train(cnn, train_loader, test_loader, loss_fn, optimizer, num_epochs, device)\n",
    "     i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 3, 9, 9) (146, 91)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
