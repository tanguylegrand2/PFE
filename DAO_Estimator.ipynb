{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Signal_generator.generate_signal import generate_X_matrix\n",
    "from Algorithmes.beamforming import beamforming_method\n",
    "from Signal_generator.generate_signal import generate_A_matrix\n",
    "from Signal_generator.generate_signal import generate_noise\n",
    "from Signal_generator.generate_signal import generate_R_hat\n",
    "from Signal_generator.generate_signal import generate_R_hat_with_phase\n",
    "from Signal_generator.generate_signal import generate_R_hat_with_phase_complex\n",
    "from Algorithmes.music import music_method\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import itertools\n",
    "# Définition des paramètres du problème\n",
    "\n",
    "nbSources = 2 # Nombre de sources  dans l'article ils fixent le nombre de sources à 2\n",
    "nbSensors = 16 # Nombre de capteurs\n",
    "nbTimePoints = 100 # Nombre de points temporels\n",
    "var_ratio_1=1 # Rapport d intensité entre les deux signaux\n",
    "var_ratio_list = [[var_ratio_1]]\n",
    "\n",
    "\n",
    "\n",
    "#Pour l'échantillon d'entraînements ils utilisent une observation de chaque combinaison d'angles d'arrivée possible pour chaque SNR level, dans le cas d'une seule source, 2G+1 observations\n",
    "#SNR ratio dans le papier est seulement low, de -20 à 0 DB avec un pas de 5\n",
    "#Petite note : si on fait un modèle pour chaque SNR level, les performances augmentent légérements, mais cela ne vaut pas l'effort effectué\n",
    "signal_noise_ratio = [-20,-15,-10,-5,0] # Rapport signal sur bruit en décibels. Si 'False', cela revient à une absence totale de bruit.\n",
    "L = nbSensors\n",
    "T = 100\n",
    "correlation_List = [[0]] # Liste des corrélations. Il y a une corrélation nécéssaire pour chaque paire distincte de sources différentes: 0 pour 1 source, 1 pour 2 sources, 3 pour 3 sources, 6 pour 4 sources etc...\n",
    "# Ordre de remplisage de la correlation_List: de gauche à droite et ligne par ligne, moitié haut-droite de la matrice uniquement, puis symétrie de ces valeurs pour la moitié bas-gauche.\n",
    "perturbation_parameter_sd = [0] #liste des perturbations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def angles_to_binary_vector(thetaList, G):\n",
    "    \"\"\"\n",
    "    Convertit une liste d'angles en un vecteur binaire représentant la présence/absence d'angles dans la grille G.\n",
    "    \n",
    "    Args:\n",
    "    - thetaList: Liste des angles d'arrivée pour un échantillon.\n",
    "    - G: Grille des angles possibles.\n",
    "    \n",
    "    Returns:\n",
    "    - Vecteur binaire des labels Z.\n",
    "    \"\"\"\n",
    "    Z = np.zeros(len(G), dtype=int)\n",
    "    for theta in thetaList:\n",
    "        index = np.searchsorted(G, theta)  # Trouver l'indice de l'angle dans la grille\n",
    "        if 0 <= index < len(G):  # S'assurer que l'indice est dans la plage valide\n",
    "            Z[index] = 1\n",
    "    return Z\n",
    "\n",
    "\n",
    "def generate_combinations(phi_max, rho, nb_sources):\n",
    "    \"\"\"Cette fonction sert à générer toutes les combinaisons d'angles possibles dans la plage de résolution\"\"\"\n",
    "    # Générer une plage de valeurs possibles pour les signaux\n",
    "    values = list(range(-int(phi_max / rho), int(phi_max / rho) + 1))\n",
    "    \n",
    "    # Générer toutes les combinaisons possibles de signaux\n",
    "    all_combinations = list(itertools.product(values, repeat=nb_sources))\n",
    "    \n",
    "    # Supprimer les combinaisons où l'ordre ne compte pas\n",
    "    unique_combinations = set()\n",
    "    for combination in all_combinations:\n",
    "        sorted_combination = tuple(sorted(combination))\n",
    "        unique_combinations.add(sorted_combination)\n",
    "    unique_combinations=list(unique_combinations)\n",
    "        \n",
    "    #supprimer les combinaisons ou deux signaux ont la même valeur\n",
    "    combination_a_supp=[]\n",
    "    for combination in unique_combinations:\n",
    "        presents=[]\n",
    "        for element in combination:\n",
    "            if element not in presents:\n",
    "                presents.append(element)\n",
    "            else:\n",
    "                combination_a_supp.append(combination)\n",
    "    for combination in combination_a_supp:\n",
    "        unique_combinations.remove(combination)\n",
    "                \n",
    "        \n",
    "    \n",
    "    return unique_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Paramètres pour la simulation\n",
    "\n",
    "num_samples = 1000  # Nombre d'échantillons à générer #16290\n",
    "L = nbSensors  # Nombre de capteurs\n",
    "T = 100  # Nombre de points temporels\n",
    "phi_max =60  # φmax\n",
    "rho = 1 # Résolution\n",
    "\n",
    "# Grille des angles\n",
    "G = np.arange(-phi_max, phi_max + rho, rho)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36300\n"
     ]
    }
   ],
   "source": [
    "#Génération du set de donnée qui comprend toutes les combinaisons possibles de tous les angles de notre grille,\n",
    "# avec tout les ratio signaux sur bruit, toutes les corrélations et toutes les calibrations\n",
    "\n",
    "def generation_donnees( phi_max : int, rho : float, SNR : list,var_ratio : list, correlation : list, perturbation_parameter_sd ):\n",
    "    angles_combination=generate_combinations(phi_max,rho,nbSources)\n",
    "    num_samples=len(angles_combination)*len(SNR)*len(correlation)*len(var_ratio)*len(perturbation_parameter_sd)\n",
    "    \n",
    "    # Initialisation des tableaux pour les données\n",
    "    all_R_hat_with_phase = np.zeros((num_samples, 3, L, L))\n",
    "    all_Z = np.zeros((num_samples, len(G)))\n",
    "    \n",
    "    #On parcourt les différents parametres possibles\n",
    "    i=0\n",
    "    for snr in SNR:\n",
    "        for var in var_ratio:\n",
    "            for corr in correlation:\n",
    "                for perturbation in perturbation_parameter_sd:\n",
    "                    # Générer les angles d'arrivée et la matrice X comme décrit précédemment\n",
    "                    for angles in angles_combination:\n",
    "                        thetaList=list(angles)\n",
    "                        X = generate_X_matrix(nbSources, L, T, thetaList, var, corr, snr, perturbation)# fonction pour générer X, ajoutez les paramètres nécessaires\n",
    "            \n",
    "                        # Calculer R_hat étendue avec phase\n",
    "                        R_hat_with_phase = generate_R_hat_with_phase(X)\n",
    "                        all_R_hat_with_phase[i] = R_hat_with_phase\n",
    "            \n",
    "                        # Calculer les labels Z pour les angles générés\n",
    "                        all_Z[i] = angles_to_binary_vector(thetaList, G)\n",
    "                        i+=1\n",
    "    return all_R_hat_with_phase, all_Z\n",
    "\n",
    "\n",
    "all_R_hat_with_phase, all_Z=generation_donnees(phi_max, rho, signal_noise_ratio,var_ratio_list, correlation_List,perturbation_parameter_sd)\n",
    "print(len(all_Z))\n",
    "\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Génération des données\\n\\n# Initialisation des tableaux pour les données\\nall_R_hat_with_phase = np.zeros((num_samples, 3, L, L))\\nall_Z = np.zeros((num_samples, len(G)))\\n\\nfor i in range(num_samples):\\n    # Générer les angles d'arrivée et la matrice X comme décrit précédemment\\n    thetaList = [np.random.uniform(-phi_max, phi_max) for _ in range(nbSources)]  # Exemple de génération d'angles\\n    var_ratio = [var_ratio_1]\\n    X = generate_X_matrix(nbSources, L, T, thetaList, var_ratio, correlation_List, 0, perturbation_parameter_sd=0)  # Votre fonction pour générer X, ajoutez les paramètres nécessaires\\n    \\n    # Calculer R_hat étendue avec phase\\n    R_hat_with_phase = generate_R_hat_with_phase(X)\\n    all_R_hat_with_phase[i] = R_hat_with_phase\\n    \\n    # Calculer les labels Z pour les angles générés\\n    all_Z[i] = angles_to_binary_vector(thetaList, G)\\n    \""
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Génération des données\n",
    "\n",
    "# Initialisation des tableaux pour les données\n",
    "all_R_hat_with_phase = np.zeros((num_samples, 3, L, L))\n",
    "all_Z = np.zeros((num_samples, len(G)))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Générer les angles d'arrivée et la matrice X comme décrit précédemment\n",
    "    thetaList = [np.random.uniform(-phi_max, phi_max) for _ in range(nbSources)]  # Exemple de génération d'angles\n",
    "    var_ratio = [var_ratio_1]\n",
    "    X = generate_X_matrix(nbSources, L, T, thetaList, var_ratio, correlation_List, 0, perturbation_parameter_sd=0)  # Votre fonction pour générer X, ajoutez les paramètres nécessaires\n",
    "    \n",
    "    # Calculer R_hat étendue avec phase\n",
    "    R_hat_with_phase = generate_R_hat_with_phase(X)\n",
    "    all_R_hat_with_phase[i] = R_hat_with_phase\n",
    "    \n",
    "    # Calculer les labels Z pour les angles générés\n",
    "    all_Z[i] = angles_to_binary_vector(thetaList, G)\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, Z_train, Z_test = train_test_split(all_R_hat_with_phase, all_Z, test_size=0.1 , random_state=42)#test_size=0.1 selon papier\n",
    "\n",
    "#Conversion des données en tenseur\n",
    "X_train = torch.from_numpy(X_train).to(dtype=torch.float32)\n",
    "X_test = torch.from_numpy(X_test).to(dtype=torch.float32)\n",
    "Z_train = torch.from_numpy(Z_train).to(dtype=torch.float32)\n",
    "Z_test = torch.from_numpy(Z_test).to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Création du dataset\n",
    "\n",
    "class DOADataset(Dataset):\n",
    "    def __init__(self, covariance_matrices, doa_labels):\n",
    "        \"\"\"\n",
    "        Initialisation du Dataset DOA.\n",
    "\n",
    "        Args:\n",
    "        - covariance_matrices (np.ndarray): Matrices de covariance étendues avec la phase.\n",
    "          Forme attendue: (nb_samples, nbSensors, nbSensors, 3) pour les parties réelle, imaginaire, et la phase.\n",
    "        - doa_labels (np.ndarray): Labels DOA sous forme de vecteurs binaires.\n",
    "          Forme attendue: (nb_samples, nb_labels), où nb_labels est le nombre de points dans la grille DOA.\n",
    "        \"\"\"\n",
    "        self.covariance_matrices = covariance_matrices\n",
    "        self.doa_labels = doa_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.covariance_matrices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      cov_matrix = self.covariance_matrices[idx]\n",
    "      angle = self.doa_labels[idx]\n",
    "\n",
    "      # Vérification si cov_matrix est déjà un ndarray, sinon le convertir\n",
    "      if not isinstance(cov_matrix, np.ndarray):\n",
    "          cov_matrix = cov_matrix.numpy()  # Convertir en tableau NumPy si ce n'est pas déjà fait\n",
    "    \n",
    "      cov_matrix = torch.from_numpy(cov_matrix).float()\n",
    "      angle = torch.tensor(angle).float()\n",
    "\n",
    "      return cov_matrix, angle\n",
    "\n",
    "\n",
    "# Exemple d'utilisation (remplacez R_hat_train/test et angles_train/test par vos données réelles)\n",
    "train_dataset = DOADataset(X_train, Z_train)\n",
    "test_dataset = DOADataset(X_test, Z_test)\n",
    "\n",
    "# Création des DataLoaders pour l'entraînement et le test, batch_size en fonction de l'article\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#Définition du device\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOACNN(\n",
      "  (conv1): Conv2d(3, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv7): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv10): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (relu6): ReLU()\n",
      "  (relu9): ReLU()\n",
      "  (relu12): ReLU()\n",
      "  (relu15): ReLU()\n",
      "  (relu18): ReLU()\n",
      "  (relu21): ReLU()\n",
      "  (dropout16): Dropout(p=0.2, inplace=False)\n",
      "  (dropout19): Dropout(p=0.2, inplace=False)\n",
      "  (dropout22): Dropout(p=0.2, inplace=False)\n",
      "  (flatten13): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc17): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc20): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc23): Linear(in_features=1024, out_features=121, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Définition du modèle\n",
    "nombre_de_classe=phi_max*2/rho+1\n",
    "nombre_de_classe=int(nombre_de_classe)\n",
    "class DOACNN(nn.Module):\n",
    "    def __init__(self, num_channels=3, num_classes=nombre_de_classe):\n",
    "        super(DOACNN, self).__init__()\n",
    "\n",
    "        # Couches convolutionnelles 2D\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, stride=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1)\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1)\n",
    "        self.conv10 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1)\n",
    "\n",
    "        # Normalisation de taille 256\n",
    "        self.norm2 = nn.BatchNorm2d(256)\n",
    "        self.norm5 = nn.BatchNorm2d(256)\n",
    "        self.norm8 = nn.BatchNorm2d(256)\n",
    "        self.norm11 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.relu3 =  nn.ReLU()\n",
    "        self.relu6 =  nn.ReLU()\n",
    "        self.relu9 =  nn.ReLU()\n",
    "        self.relu12 =  nn.ReLU()\n",
    "        self.relu15 =  nn.ReLU()\n",
    "        self.relu18 =  nn.ReLU()\n",
    "        self.relu21 =  nn.ReLU()\n",
    "\n",
    "        # Couches Dropout\n",
    "        self.dropout16 = nn.Dropout(0.2)\n",
    "        self.dropout19 = nn.Dropout(0.2)\n",
    "        self.dropout22 = nn.Dropout(0.2)\n",
    "\n",
    "        # Couche d'aplatissement\n",
    "        self.flatten13 = nn.Flatten()\n",
    "\n",
    "        # Couches entièrement connectées (FC)\n",
    "        self.fc14 = None\n",
    "        self.fc17 = nn.Linear(in_features=4096, out_features=2048)\n",
    "        self.fc20 = nn.Linear(in_features=2048, out_features=1024)\n",
    "        self.fc23 = nn.Linear(in_features=1024, out_features=num_classes)\n",
    "\n",
    "        # Couche de sortie Sigmoid\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.norm5(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.norm8(x)\n",
    "        x = self.relu9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.norm11(x)\n",
    "        x = self.relu12(x)\n",
    "        x = self.flatten13(x)\n",
    "        self.fc14=nn.Linear(in_features=x.size(1), out_features=4096)\n",
    "        x = self.fc14(x)\n",
    "        x = self.relu15(x)\n",
    "        x = self.dropout16(x)\n",
    "        x = self.fc17(x)\n",
    "        x = self.relu18(x)\n",
    "        x = self.dropout19(x)\n",
    "        x = self.fc20(x)\n",
    "        x = self.relu21(x)\n",
    "        x = self.dropout22(x)\n",
    "        x = self.fc23(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Création d'une instance du modèle\n",
    "model = DOACNN()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Définition des hyperparamètres, choisis en fonction de l'article DOA estimator\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30 # à monter à 200 pour le training final selon l'article\n",
    "loss_fn = nn.BCELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boucle d'entraînement\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Display loss from time to time\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss: >7f}  [{current: >5d} / {size: >5d}]\")\n",
    "\n",
    "\n",
    "#Boucle de tests\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct, MSE = 0, 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            #print( f\"pred{pred.shape}\")\n",
    "            _, angles_predit = pred.topk(nbSources, dim=1)\n",
    "            _,angles_correct=top_values, top_indices = y.topk(nbSources, dim=1)\n",
    "            correct += (angles_predit==angles_correct).type(torch.float).sum().item()\n",
    "            #Calcul de la somme des carrés des différences entre prédictions et réalité pour la RMSE\n",
    "            taille_du_batch=pred.shape[0]\n",
    "            for element in range(taille_du_batch):\n",
    "                for angle in range(nbSources):\n",
    "                    MSE+=(angles_correct[element, angle]-angles_predit[element, angle])**2\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    MSE=MSE/(len(test_dataloader)*nbSources)\n",
    "    RMSE=math.sqrt(MSE)\n",
    "    print(f\"\\nTest set: \\n  Accuracy: {(100 * correct): >0.1f}%, Avg loss: {test_loss: >8f} \\n RMSE : {RMSE: >8f}\")\n",
    "    return test_loss, correct\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction d'entraînement et tests\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device):\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        test_loop(test_dataloader, model, loss_fn, device)\n",
    "        scheduler.step()\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(param_group['lr'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legra\\AppData\\Local\\Temp\\ipykernel_18396\\1795750363.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  angle = torch.tensor(angle).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.691040  [   32 / 32670]\n",
      "loss: 0.091166  [ 3232 / 32670]\n",
      "loss: 0.089459  [ 6432 / 32670]\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device)\n",
    "print('Entraînement terminé!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.7375e-34, 1.8518e-14, 2.6936e-17, 3.1046e-16, 9.6041e-16, 1.2256e-14,\n",
      "         6.8940e-16, 2.6410e-15, 1.7165e-16, 9.3808e-14, 5.0826e-15, 7.4618e-15,\n",
      "         5.6484e-15, 1.5161e-15, 5.3596e-17, 2.3702e-15, 1.9469e-15, 1.4362e-15,\n",
      "         8.2665e-17, 1.0159e-16, 1.0833e-17, 1.8269e-17, 5.2858e-15, 4.3220e-14,\n",
      "         2.2428e-16, 1.5541e-17, 8.3199e-15, 1.1789e-16, 1.3270e-15, 1.6644e-12,\n",
      "         2.7343e-14, 7.8522e-14, 2.0262e-13, 9.5277e-18, 4.8188e-15, 1.0483e-15,\n",
      "         9.4673e-15, 5.0353e-15, 7.9463e-14, 2.9590e-15, 1.1476e-16, 1.7035e-15,\n",
      "         1.5611e-18, 2.5234e-17, 3.7850e-15, 6.3808e-15, 3.3663e-15, 6.4861e-16,\n",
      "         3.8910e-14, 1.8267e-15, 7.0541e-16, 3.3127e-17, 2.8181e-15, 4.7950e-15,\n",
      "         5.7732e-14, 7.0923e-16, 2.2599e-14, 8.2273e-14, 1.1189e-14, 7.6855e-14,\n",
      "         3.4185e-15, 9.3386e-15, 8.5730e-14, 1.9839e-15, 4.3691e-15, 1.2137e-15,\n",
      "         2.5137e-16, 6.3013e-16, 7.3589e-15, 2.0876e-14, 2.2824e-15, 2.6719e-14,\n",
      "         1.0002e-14, 6.5146e-16, 2.7152e-14, 1.2963e-15, 2.7971e-15, 9.2556e-17,\n",
      "         2.3563e-15, 2.2696e-14, 2.3676e-14, 2.9602e-16, 2.3539e-16, 1.3874e-15,\n",
      "         4.7112e-16, 4.5647e-17, 2.3094e-14, 1.3191e-13, 7.8746e-16, 1.6479e-15,\n",
      "         1.7182e-15, 4.6778e-15, 4.7853e-14, 4.4217e-16, 7.1568e-17, 7.3517e-16,\n",
      "         8.2913e-16, 8.6158e-15, 9.4723e-14, 7.7327e-16, 8.0789e-16, 8.4225e-15,\n",
      "         3.1481e-15, 2.1123e-14, 7.5303e-15, 1.6553e-15, 1.3063e-15, 8.4476e-15,\n",
      "         2.7773e-15, 5.1380e-15, 5.9173e-16, 4.8082e-14, 1.1772e-13, 1.0420e-14,\n",
      "         2.0210e-14, 4.1460e-13, 6.8047e-15, 1.1230e-13, 8.8223e-14, 1.0271e-16,\n",
      "         3.7419e-15]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[ 29, 115]])\n"
     ]
    }
   ],
   "source": [
    "x= generate_X_matrix(nbSources, L, T, [-59,59], [1], correlation_List, 20, perturbation_parameter_sd=0)\n",
    "R_hat_with_phase = generate_R_hat_with_phase(x)\n",
    "X_train = torch.from_numpy(R_hat_with_phase).to(dtype=torch.float32)\n",
    "X_train=X_train.unsqueeze(0)\n",
    "angle_predit=model(X_train)\n",
    "print(angle_predit)\n",
    "_, angles_predit = angle_predit.topk(nbSources, dim=1)\n",
    "sorted_angles, _ = torch.sort(angles_predit)\n",
    "print(sorted_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOACNN(\n",
      "  (conv1): Conv2d(3, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv7): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv10): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (relu6): ReLU()\n",
      "  (relu9): ReLU()\n",
      "  (relu12): ReLU()\n",
      "  (relu15): ReLU()\n",
      "  (relu18): ReLU()\n",
      "  (relu21): ReLU()\n",
      "  (dropout16): Dropout(p=0.2, inplace=False)\n",
      "  (dropout19): Dropout(p=0.2, inplace=False)\n",
      "  (dropout22): Dropout(p=0.2, inplace=False)\n",
      "  (flatten13): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc17): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc20): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc23): Linear(in_features=1024, out_features=121, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (fc14): Linear(in_features=4096, out_features=4096, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 256, 7, 7]           7,168\n",
      "       BatchNorm2d-2            [-1, 256, 7, 7]             512\n",
      "              ReLU-3            [-1, 256, 7, 7]               0\n",
      "            Conv2d-4            [-1, 256, 6, 6]         262,400\n",
      "       BatchNorm2d-5            [-1, 256, 6, 6]             512\n",
      "              ReLU-6            [-1, 256, 6, 6]               0\n",
      "            Conv2d-7            [-1, 256, 5, 5]         262,400\n",
      "       BatchNorm2d-8            [-1, 256, 5, 5]             512\n",
      "              ReLU-9            [-1, 256, 5, 5]               0\n",
      "           Conv2d-10            [-1, 256, 4, 4]         262,400\n",
      "      BatchNorm2d-11            [-1, 256, 4, 4]             512\n",
      "             ReLU-12            [-1, 256, 4, 4]               0\n",
      "          Flatten-13                 [-1, 4096]               0\n",
      "             ReLU-14                 [-1, 4096]               0\n",
      "          Dropout-15                 [-1, 4096]               0\n",
      "           Linear-16                 [-1, 2048]       8,390,656\n",
      "             ReLU-17                 [-1, 2048]               0\n",
      "          Dropout-18                 [-1, 2048]               0\n",
      "           Linear-19                 [-1, 1024]       2,098,176\n",
      "             ReLU-20                 [-1, 1024]               0\n",
      "          Dropout-21                 [-1, 1024]               0\n",
      "           Linear-22                  [-1, 121]         124,025\n",
      "          Sigmoid-23                  [-1, 121]               0\n",
      "================================================================\n",
      "Total params: 11,409,273\n",
      "Trainable params: 11,409,273\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.90\n",
      "Params size (MB): 43.52\n",
      "Estimated Total Size (MB): 44.43\n",
      "----------------------------------------------------------------\n",
      "Layer: conv1.weight | Size: torch.Size([256, 3, 3, 3])\n",
      "Layer: conv1.bias | Size: torch.Size([256])\n",
      "Layer: conv4.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv4.bias | Size: torch.Size([256])\n",
      "Layer: conv7.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv7.bias | Size: torch.Size([256])\n",
      "Layer: conv10.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv10.bias | Size: torch.Size([256])\n",
      "Layer: norm2.weight | Size: torch.Size([256])\n",
      "Layer: norm2.bias | Size: torch.Size([256])\n",
      "Layer: norm5.weight | Size: torch.Size([256])\n",
      "Layer: norm5.bias | Size: torch.Size([256])\n",
      "Layer: norm8.weight | Size: torch.Size([256])\n",
      "Layer: norm8.bias | Size: torch.Size([256])\n",
      "Layer: norm11.weight | Size: torch.Size([256])\n",
      "Layer: norm11.bias | Size: torch.Size([256])\n",
      "Layer: fc17.weight | Size: torch.Size([2048, 4096])\n",
      "Layer: fc17.bias | Size: torch.Size([2048])\n",
      "Layer: fc20.weight | Size: torch.Size([1024, 2048])\n",
      "Layer: fc20.bias | Size: torch.Size([1024])\n",
      "Layer: fc23.weight | Size: torch.Size([121, 1024])\n",
      "Layer: fc23.bias | Size: torch.Size([121])\n",
      "Layer: fc14.weight | Size: torch.Size([4096, 4096])\n",
      "Layer: fc14.bias | Size: torch.Size([4096])\n"
     ]
    }
   ],
   "source": [
    "#Quelques informations sur notre modèle : \n",
    "\n",
    "print(model)\n",
    "\n",
    "summary(model, input_size=(3, nbSensors, nbSensors))\n",
    "\n",
    "#Poids des paramètres :\n",
    "\n",
    "\n",
    "# Initialiser le compteur de paramètres\n",
    "total_params = 0\n",
    "\n",
    "# Boucle à travers les paramètres de votre modèle\n",
    "for param in model.parameters():\n",
    "    # Vérifier si le paramètre nécessite un gradient (c'est-à-dire s'il est entraînable)\n",
    "    if param.requires_grad:\n",
    "        # Compter le nombre de valeurs dans le paramètre\n",
    "        total_params += param.numel()\n",
    "\n",
    "# Boucle à travers les paramètres de votre modèle\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#On sauvegarde le modèle pour l\\'utiliser dans un autre module python\\nfrom Models.compare import *\\nsave_model_hyperparams_and_metadata(model, hyperparameters=[{\"A\" : \"a\"}], training_metadata=[{\"A\" : \"a\"}], directory_name=\"DaO_estimator\")\\n'"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#On sauvegarde le modèle pour l'utiliser dans un autre module python\n",
    "from Models.compare import *\n",
    "save_model_hyperparams_and_metadata(model, hyperparameters=[{\"A\" : \"a\"}], training_metadata=[{\"A\" : \"a\"}], directory_name=\"DaO_estimator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DOACNN:\n\tUnexpected key(s) in state_dict: \"fc14.weight\", \"fc14.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[386], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m DaO_model,_\u001b[38;5;241m=\u001b[39m\u001b[43mload_model_and_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDaO_estimator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDOACNN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mDaO_method\u001b[39m(X,nbSensors, nbSources):\n\u001b[0;32m      3\u001b[0m     R_hat_with_phase \u001b[38;5;241m=\u001b[39m generate_R_hat_with_phase(X)\n",
      "File \u001b[1;32mc:\\Users\\legra\\Documents pc\\ENSAI\\3A\\PFE\\code fonctionnel\\Models\\compare.py:55\u001b[0m, in \u001b[0;36mload_model_and_hyperparams\u001b[1;34m(directory_name, model_class)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Charger l'état du modèle\u001b[39;00m\n\u001b[0;32m     54\u001b[0m model \u001b[38;5;241m=\u001b[39m model_class()  \u001b[38;5;66;03m# Créer une instance de la classe du modèle\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Mettre le modèle en mode évaluation\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Charger les hyperparamètres\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DOACNN:\n\tUnexpected key(s) in state_dict: \"fc14.weight\", \"fc14.bias\". "
     ]
    }
   ],
   "source": [
    "DaO_model,_=load_model_and_hyperparams(\"DaO_estimator\", model_class=DOACNN)\n",
    "def DaO_method(X,nbSensors, nbSources):\n",
    "    R_hat_with_phase = generate_R_hat_with_phase(X)\n",
    "    X_train = torch.from_numpy(R_hat_with_phase).to(dtype=torch.float32)\n",
    "    X_train=X_train.unsqueeze(0)\n",
    "    pred=DaO_model(X_train)\n",
    "    _, angles_predit = pred.topk(nbSources, dim=1)\n",
    "    sorted_angles, _ = torch.sort(angles_predit)\n",
    "    return list(sorted_angles)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([72, 74])]\n"
     ]
    }
   ],
   "source": [
    "x= generate_X_matrix(nbSources, L, T, [-10,10], [1], correlation_List, 20, perturbation_parameter_sd=0)\n",
    "angle_predit=DaO_method(x,nbSensors,nbSources)\n",
    "print(angle_predit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPuis voici la marche à suivre pour charger le modèle entrainé dans un nouveau module python\\n\\nimport torch\\nimport torch.nn as nn\\n\\n# Définir la classe de votre modèle (avec la même architecture que celle utilisée pour l'entraînement)\\nclass VotreModele(nn.Module):\\n    def __init__(self, ...):  # Définir les mêmes couches que celles utilisées pour l'entraînement\\n        super(VotreModele, self).__init__()\\n        ...\\n\\n# Créer une instance de votre modèle\\nmodel = VotreModele(...)\\n\\n# Charger les poids du modèle entraîné\\nmodel.load_state_dict(torch.load('chemin/vers/votre/modele.pth'))\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sauvegarder le modèle pour l'utiliser dans un autre module python:\n",
    "#torch.save(model.state_dict(), 'C:\\\\Users\\\\legra\\\\Documents pc\\\\ENSAI\\\\3A\\\\PFE\\\\model.pth')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Puis voici la marche à suivre pour charger le modèle entrainé dans un nouveau module python\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Définir la classe de votre modèle (avec la même architecture que celle utilisée pour l'entraînement)\n",
    "class VotreModele(nn.Module):\n",
    "    def __init__(self, ...):  # Définir les mêmes couches que celles utilisées pour l'entraînement\n",
    "        super(VotreModele, self).__init__()\n",
    "        ...\n",
    "\n",
    "# Créer une instance de votre modèle\n",
    "model = VotreModele(...)\n",
    "\n",
    "# Charger les poids du modèle entraîné\n",
    "model.load_state_dict(torch.load('chemin/vers/votre/modele.pth'))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test du modèle complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_X_matrix() missing 1 required positional argument: 'perturbation_parameter_sd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m thetaList_complex \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39mphi_max, phi_max) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nbSources)]  \u001b[38;5;66;03m# Exemple de génération d'angles\u001b[39;00m\n\u001b[0;32m     10\u001b[0m varList_complex \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1000000000000\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nbSources)]\n\u001b[1;32m---> 11\u001b[0m X_complex \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_X_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbSources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthetaList_complex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvarList_complex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrelation_List\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal_noise_ratio\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Votre fonction pour générer X, ajoutez les paramètres nécessaires\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calculer R_hat étendue avec phase\u001b[39;00m\n\u001b[0;32m     14\u001b[0m R_hat_with_phase_complex \u001b[38;5;241m=\u001b[39m generate_R_hat_with_phase_complex(X_complex)\n",
      "\u001b[1;31mTypeError\u001b[0m: generate_X_matrix() missing 1 required positional argument: 'perturbation_parameter_sd'"
     ]
    }
   ],
   "source": [
    "#Génération des données\n",
    "\n",
    "# Initialisation des tableaux pour les données\n",
    "all_R_hat_with_phase_complex = np.zeros((num_samples, 2, L, L))\n",
    "all_Z_complex = np.zeros((num_samples, len(G)))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Générer les angles d'arrivée et la matrice X comme décrit précédemment\n",
    "    thetaList_complex = [np.random.uniform(-phi_max, phi_max) for _ in range(nbSources)]  # Exemple de génération d'angles\n",
    "    varList_complex = [np.random.uniform(0, 1000000000000) for _ in range(nbSources)]\n",
    "    X_complex = generate_X_matrix(nbSources, L, T, thetaList_complex, varList_complex, correlation_List, signal_noise_ratio)  # Votre fonction pour générer X, ajoutez les paramètres nécessaires\n",
    "    \n",
    "    # Calculer R_hat étendue avec phase\n",
    "    R_hat_with_phase_complex = generate_R_hat_with_phase_complex(X_complex)\n",
    "    all_R_hat_with_phase_complex[i] = R_hat_with_phase_complex\n",
    "    \n",
    "    # Calculer les labels Z pour les angles générés\n",
    "    all_Z_complex[i] = angles_to_binary_vector(thetaList_complex, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train_complex, X_test_complex, Z_train_complex, Z_test_complex = train_test_split(all_R_hat_with_phase_complex, all_Z_complex, test_size=0.1 , random_state=42)#test_size=0.1 selon papier\n",
    "\n",
    "#Conversion des données en tenseur\n",
    "X_train_complex = torch.from_numpy(X_train_complex).to(dtype=torch.complex64)\n",
    "X_test_complex = torch.from_numpy(X_test_complex).to(dtype=torch.complex64)\n",
    "Z_train_complex = torch.from_numpy(Z_train_complex).to(dtype=torch.complex64)\n",
    "Z_test_complex = torch.from_numpy(Z_test_complex).to(dtype=torch.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du dataset\n",
    "\n",
    "class DOADatasetComplex(Dataset):\n",
    "    def __init__(self, covariance_matrices, doa_labels):\n",
    "        \"\"\"\n",
    "        Initialisation du Dataset DOA.\n",
    "\n",
    "        Args:\n",
    "        - covariance_matrices (np.ndarray): Matrices de covariance étendues avec la phase.\n",
    "          Forme attendue: (nb_samples, nbSensors, nbSensors, 3) pour les parties réelle, imaginaire, et la phase.\n",
    "        - doa_labels (np.ndarray): Labels DOA sous forme de vecteurs binaires.\n",
    "          Forme attendue: (nb_samples, nb_labels), où nb_labels est le nombre de points dans la grille DOA.\n",
    "        \"\"\"\n",
    "        self.covariance_matrices = covariance_matrices\n",
    "        self.doa_labels = doa_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.covariance_matrices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      cov_matrix = self.covariance_matrices[idx]\n",
    "      angle = self.doa_labels[idx]\n",
    "\n",
    "      # Vérification si cov_matrix est déjà un ndarray, sinon le convertir\n",
    "      if not isinstance(cov_matrix, np.ndarray):\n",
    "          cov_matrix = cov_matrix.numpy()  # Convertir en tableau NumPy si ce n'est pas déjà fait\n",
    "    \n",
    "      cov_matrix = torch.from_numpy(cov_matrix).to(dtype=torch.complex64)\n",
    "      angle = torch.tensor(angle).to(dtype=torch.complex64)\n",
    "\n",
    "      return cov_matrix, angle\n",
    "\n",
    "\n",
    "# Exemple d'utilisation (remplacez R_hat_train/test et angles_train/test par vos données réelles)\n",
    "train_dataset_complex = DOADatasetComplex(X_train_complex, Z_train_complex)\n",
    "test_dataset_complex = DOADatasetComplex(X_test_complex, Z_test_complex)\n",
    "\n",
    "# Création des DataLoaders pour l'entraînement et le test, batch_size en fonction de l'article\n",
    "train_dataloader_complex = DataLoader(train_dataset_complex, batch_size=32, shuffle=True)\n",
    "test_dataloader_complex = DataLoader(test_dataset_complex, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOACNNCOMPLEX(\n",
      "  (conv1): Conv2d(2, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv7): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv10): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (relu6): ReLU()\n",
      "  (relu9): ReLU()\n",
      "  (relu12): ReLU()\n",
      "  (relu15): ReLU()\n",
      "  (relu18): ReLU()\n",
      "  (relu21): ReLU()\n",
      "  (dropout16): Dropout(p=0.2, inplace=False)\n",
      "  (dropout19): Dropout(p=0.2, inplace=False)\n",
      "  (dropout22): Dropout(p=0.2, inplace=False)\n",
      "  (flatten13): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc14): Linear(in_features=256, out_features=4096, bias=True)\n",
      "  (fc17): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc20): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc23): Linear(in_features=1024, out_features=91, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Définition du modèle\n",
    "\n",
    "class DOACNNCOMPLEX(nn.Module):\n",
    "    def __init__(self, num_channels=2, num_classes=phi_max*2+1):\n",
    "        super(DOACNNCOMPLEX, self).__init__()\n",
    "\n",
    "        # Couches convolutionnelles 2D\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=256, kernel_size=3, stride=2, bias=True)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1, bias=True)\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1, bias=True)\n",
    "        self.conv10 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1, bias=True)\n",
    "\n",
    "        # Normalisation de taille 256\n",
    "        self.norm2 = nn.BatchNorm2d(256)\n",
    "        self.norm5 = nn.BatchNorm2d(256)\n",
    "        self.norm8 = nn.BatchNorm2d(256)\n",
    "        self.norm11 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.relu3 =  nn.ReLU()\n",
    "        self.relu6 =  nn.ReLU()\n",
    "        self.relu9 =  nn.ReLU()\n",
    "        self.relu12 =  nn.ReLU()\n",
    "        self.relu15 =  nn.ReLU()\n",
    "        self.relu18 =  nn.ReLU()\n",
    "        self.relu21 =  nn.ReLU()\n",
    "\n",
    "        # Couches Dropout\n",
    "        self.dropout16 = nn.Dropout(0.2)\n",
    "        self.dropout19 = nn.Dropout(0.2)\n",
    "        self.dropout22 = nn.Dropout(0.2)\n",
    "\n",
    "        # Couche d'aplatissement\n",
    "        self.flatten13 = nn.Flatten()\n",
    "\n",
    "        # Couches entièrement connectées (FC)\n",
    "        self.fc14 = nn.Linear(in_features=256 , out_features=4096)\n",
    "        self.fc17 = nn.Linear(in_features=4096, out_features=2048)\n",
    "        self.fc20 = nn.Linear(in_features=2048, out_features=1024)\n",
    "        self.fc23 = nn.Linear(in_features=1024, out_features=num_classes)\n",
    "\n",
    "        # Couche de sortie Sigmoid\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.norm5(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.norm8(x)\n",
    "        x = self.relu9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.norm11(x)\n",
    "        x = self.relu12(x)\n",
    "        x = self.flatten13(x)\n",
    "        x = self.fc14(x)\n",
    "        x = self.relu15(x)\n",
    "        x = self.dropout16(x)\n",
    "        x = self.fc17(x)\n",
    "        x = self.relu18(x)\n",
    "        x = self.dropout19(x)\n",
    "        x = self.fc20(x)\n",
    "        x = self.relu21(x)\n",
    "        x = self.dropout22(x)\n",
    "        x = self.fc23(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Création d'une instance du modèle\n",
    "modelComplex = DOACNNCOMPLEX()\n",
    "print(modelComplex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legra\\AppData\\Local\\Temp\\ipykernel_25528\\3472206976.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  angle = torch.tensor(angle).to(dtype=torch.complex64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (struct c10::complex<float>) and bias type (float) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelComplex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader_complex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader_complex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntraînement terminé!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     test_loop(test_dataloader, model, loss_fn, device)\n\u001b[0;32m      8\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Compute prediction and loss\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 45\u001b[0m, in \u001b[0;36mDOACNNCOMPLEX.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 45\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)\n\u001b[0;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu3(x)\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (struct c10::complex<float>) and bias type (float) should be the same"
     ]
    }
   ],
   "source": [
    "train(modelComplex, train_dataloader_complex, test_dataloader_complex, loss_fn, optimizer, num_epochs, device)\n",
    "print('Entraînement terminé!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOACNNCOMPLEX(\n",
      "  (conv1): Conv2d(2, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv7): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv10): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (relu6): ReLU()\n",
      "  (relu9): ReLU()\n",
      "  (relu12): ReLU()\n",
      "  (relu15): ReLU()\n",
      "  (relu18): ReLU()\n",
      "  (relu21): ReLU()\n",
      "  (dropout16): Dropout(p=0.2, inplace=False)\n",
      "  (dropout19): Dropout(p=0.2, inplace=False)\n",
      "  (dropout22): Dropout(p=0.2, inplace=False)\n",
      "  (flatten13): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc14): Linear(in_features=256, out_features=4096, bias=True)\n",
      "  (fc17): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc20): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc23): Linear(in_features=1024, out_features=91, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 256, 4, 4]           4,864\n",
      "       BatchNorm2d-2            [-1, 256, 4, 4]             512\n",
      "              ReLU-3            [-1, 256, 4, 4]               0\n",
      "            Conv2d-4            [-1, 256, 3, 3]         262,400\n",
      "       BatchNorm2d-5            [-1, 256, 3, 3]             512\n",
      "              ReLU-6            [-1, 256, 3, 3]               0\n",
      "            Conv2d-7            [-1, 256, 2, 2]         262,400\n",
      "       BatchNorm2d-8            [-1, 256, 2, 2]             512\n",
      "              ReLU-9            [-1, 256, 2, 2]               0\n",
      "           Conv2d-10            [-1, 256, 1, 1]         262,400\n",
      "      BatchNorm2d-11            [-1, 256, 1, 1]             512\n",
      "             ReLU-12            [-1, 256, 1, 1]               0\n",
      "          Flatten-13                  [-1, 256]               0\n",
      "           Linear-14                 [-1, 4096]       1,052,672\n",
      "             ReLU-15                 [-1, 4096]               0\n",
      "          Dropout-16                 [-1, 4096]               0\n",
      "           Linear-17                 [-1, 2048]       8,390,656\n",
      "             ReLU-18                 [-1, 2048]               0\n",
      "          Dropout-19                 [-1, 2048]               0\n",
      "           Linear-20                 [-1, 1024]       2,098,176\n",
      "             ReLU-21                 [-1, 1024]               0\n",
      "          Dropout-22                 [-1, 1024]               0\n",
      "           Linear-23                   [-1, 91]          93,275\n",
      "          Sigmoid-24                   [-1, 91]               0\n",
      "================================================================\n",
      "Total params: 12,428,891\n",
      "Trainable params: 12,428,891\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.34\n",
      "Params size (MB): 47.41\n",
      "Estimated Total Size (MB): 47.76\n",
      "----------------------------------------------------------------\n",
      "Layer: conv1.weight | Size: torch.Size([256, 2, 3, 3])\n",
      "Layer: conv1.bias | Size: torch.Size([256])\n",
      "Layer: conv4.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv4.bias | Size: torch.Size([256])\n",
      "Layer: conv7.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv7.bias | Size: torch.Size([256])\n",
      "Layer: conv10.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv10.bias | Size: torch.Size([256])\n",
      "Layer: norm2.weight | Size: torch.Size([256])\n",
      "Layer: norm2.bias | Size: torch.Size([256])\n",
      "Layer: norm5.weight | Size: torch.Size([256])\n",
      "Layer: norm5.bias | Size: torch.Size([256])\n",
      "Layer: norm8.weight | Size: torch.Size([256])\n",
      "Layer: norm8.bias | Size: torch.Size([256])\n",
      "Layer: norm11.weight | Size: torch.Size([256])\n",
      "Layer: norm11.bias | Size: torch.Size([256])\n",
      "Layer: fc14.weight | Size: torch.Size([4096, 256])\n",
      "Layer: fc14.bias | Size: torch.Size([4096])\n",
      "Layer: fc17.weight | Size: torch.Size([2048, 4096])\n",
      "Layer: fc17.bias | Size: torch.Size([2048])\n",
      "Layer: fc20.weight | Size: torch.Size([1024, 2048])\n",
      "Layer: fc20.bias | Size: torch.Size([1024])\n",
      "Layer: fc23.weight | Size: torch.Size([91, 1024])\n",
      "Layer: fc23.bias | Size: torch.Size([91])\n"
     ]
    }
   ],
   "source": [
    "#Quelques informations sur notre modèle : \n",
    "\n",
    "print(modelComplex)\n",
    "\n",
    "summary(modelComplex, input_size=(2, nbSensors, nbSensors))\n",
    "\n",
    "#Poids des paramètres :\n",
    "\n",
    "\n",
    "# Initialiser le compteur de paramètres\n",
    "total_params_complex = 0\n",
    "\n",
    "# Boucle à travers les paramètres de votre modèle\n",
    "for param in modelComplex.parameters():\n",
    "    # Vérifier si le paramètre nécessite un gradient (c'est-à-dire s'il est entraînable)\n",
    "    if param.requires_grad:\n",
    "        # Compter le nombre de valeurs dans le paramètre\n",
    "        total_params_complex += param.numel()\n",
    "\n",
    "# Boucle à travers les paramètres de votre modèle\n",
    "for name, param in modelComplex.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
