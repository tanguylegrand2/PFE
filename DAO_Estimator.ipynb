{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Signal_generator.generate_signal import generate_X_matrix\n",
    "from Algorithmes.beamforming import beamforming_method\n",
    "from Signal_generator.generate_signal import generate_A_matrix\n",
    "from Signal_generator.generate_signal import generate_noise\n",
    "from Signal_generator.generate_signal import generate_R_hat\n",
    "from Signal_generator.generate_signal import generate_R_hat_with_phase\n",
    "from Signal_generator.generate_signal import generate_R_hat_with_phase_complex\n",
    "from Algorithmes.music import music_method\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import itertools\n",
    "# Définition des paramètres du problème\n",
    "\n",
    "nbSources = 2 # Nombre de sources  dans l'article ils fixent le nombre de sources à 2\n",
    "nbSensors = 16 # Nombre de capteurs\n",
    "nbTimePoints = 100 # Nombre de points temporels\n",
    "var_ratio_1=1 # Rapport d intensité entre les deux signaux\n",
    "\n",
    "\n",
    "\n",
    "#Pour l'échantillon d'entraînements ils utilisent une observation de chaque combinaison d'angles d'arrivée possible pour chaque SNR level, dans le cas d'une seule source, 2G+1 observations\n",
    "#SNR ratio dans le papier est seulement low, de -20 à 0 DB avec un pas de 5\n",
    "#Petite note : si on fait un modèle pour chaque SNR level, les performances augmentent légérements, mais cela ne vaut pas l'effort effectué\n",
    "signal_noise_ratio = [-20,-15,-10,-5,0] # Rapport signal sur bruit en décibels. Si 'False', cela revient à une absence totale de bruit.\n",
    "L = nbSensors\n",
    "T = 100\n",
    "correlation_List = [0] # Liste des corrélations. Il y a une corrélation nécéssaire pour chaque paire distincte de sources différentes: 0 pour 1 source, 1 pour 2 sources, 3 pour 3 sources, 6 pour 4 sources etc...\n",
    "# Ordre de remplisage de la correlation_List: de gauche à droite et ligne par ligne, moitié haut-droite de la matrice uniquement, puis symétrie de ces valeurs pour la moitié bas-gauche.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def angles_to_binary_vector(thetaList, G):\n",
    "    \"\"\"\n",
    "    Convertit une liste d'angles en un vecteur binaire représentant la présence/absence d'angles dans la grille G.\n",
    "    \n",
    "    Args:\n",
    "    - thetaList: Liste des angles d'arrivée pour un échantillon.\n",
    "    - G: Grille des angles possibles.\n",
    "    \n",
    "    Returns:\n",
    "    - Vecteur binaire des labels Z.\n",
    "    \"\"\"\n",
    "    Z = np.zeros(len(G), dtype=int)\n",
    "    for theta in thetaList:\n",
    "        index = np.searchsorted(G, theta)  # Trouver l'indice de l'angle dans la grille\n",
    "        if 0 <= index < len(G):  # S'assurer que l'indice est dans la plage valide\n",
    "            Z[index] = 1\n",
    "    return Z\n",
    "\n",
    "\n",
    "def generate_combinations(phi_max, rho, nb_sources):\n",
    "    \"\"\"Cette fonction sert à générer toutes les combinaisons d'angles possibles dans la plage de résolution\"\"\"\n",
    "    # Générer une plage de valeurs possibles pour les signaux\n",
    "    values = list(range(-int(phi_max / rho), int(phi_max / rho) + 1))\n",
    "    \n",
    "    # Générer toutes les combinaisons possibles de signaux\n",
    "    all_combinations = list(itertools.product(values, repeat=nb_sources))\n",
    "    \n",
    "    # Supprimer les combinaisons où l'ordre ne compte pas\n",
    "    unique_combinations = set()\n",
    "    for combination in all_combinations:\n",
    "        sorted_combination = tuple(sorted(combination))\n",
    "        unique_combinations.add(sorted_combination)\n",
    "    unique_combinations=list(unique_combinations)\n",
    "        \n",
    "    #supprimer les combinaisons ou deux signaux ont la même valeur\n",
    "    combination_a_supp=[]\n",
    "    for combination in unique_combinations:\n",
    "        presents=[]\n",
    "        for element in combination:\n",
    "            if element not in presents:\n",
    "                presents.append(element)\n",
    "            else:\n",
    "                combination_a_supp.append(combination)\n",
    "    for combination in combination_a_supp:\n",
    "        unique_combinations.remove(combination)\n",
    "                \n",
    "        \n",
    "    \n",
    "    return unique_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Paramètres pour la simulation\n",
    "\n",
    "num_samples = 1000  # Nombre d'échantillons à générer #16290\n",
    "L = nbSensors  # Nombre de capteurs\n",
    "T = 100  # Nombre de points temporels\n",
    "phi_max =60  # φmax\n",
    "rho = 1 # Résolution\n",
    "\n",
    "# Grille des angles\n",
    "G = np.arange(-phi_max, phi_max + rho, rho)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Génération du set de donnée qui comprend toutes les combinaisons possibles de tous les angles de notre grille,\n",
    "# avec tout les ratio signaux sur bruit, toutes les corrélations et toutes les calibrations\n",
    "\n",
    "def generation_donnees( phi_max : int, rho : float, SNR : list, correlation : list, calibration ):\n",
    "    angles_combination=generate_combinations(phi_max,rho,nbSources)\n",
    "    num_samples=len(angles_combination)*len(SNR)\n",
    "    \n",
    "    # Initialisation des tableaux pour les données\n",
    "    all_R_hat_with_phase = np.zeros((num_samples, 3, L, L))\n",
    "    all_Z = np.zeros((num_samples, len(G)))\n",
    "    \n",
    "    #On parcourt les différents SNR possibles\n",
    "    i=0\n",
    "    for snr in SNR:\n",
    "        # Générer les angles d'arrivée et la matrice X comme décrit précédemment\n",
    "        for angles in angles_combination:\n",
    "            thetaList=list(angles)\n",
    "            var_ratio = [var_ratio_1]\n",
    "            X = generate_X_matrix(nbSources, L, T, thetaList, var_ratio, correlation_List, snr, perturbation_parameter_sd=0)# fonction pour générer X, ajoutez les paramètres nécessaires\n",
    "            \n",
    "            # Calculer R_hat étendue avec phase\n",
    "            R_hat_with_phase = generate_R_hat_with_phase(X)\n",
    "            all_R_hat_with_phase[i] = R_hat_with_phase\n",
    "            \n",
    "            # Calculer les labels Z pour les angles générés\n",
    "            all_Z[i] = angles_to_binary_vector(thetaList, G)\n",
    "            i+=1\n",
    "    return all_R_hat_with_phase, all_Z\n",
    "\n",
    "\n",
    "all_R_hat_with_phase, all_Z=generation_donnees(phi_max, rho, signal_noise_ratio,correlation_List,[])\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Génération des données\n",
    "\n",
    "# Initialisation des tableaux pour les données\n",
    "all_R_hat_with_phase = np.zeros((num_samples, 3, L, L))\n",
    "all_Z = np.zeros((num_samples, len(G)))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Générer les angles d'arrivée et la matrice X comme décrit précédemment\n",
    "    thetaList = [np.random.uniform(-phi_max, phi_max) for _ in range(nbSources)]  # Exemple de génération d'angles\n",
    "    var_ratio = [var_ratio_1]\n",
    "    X = generate_X_matrix(nbSources, L, T, thetaList, var_ratio, correlation_List, 0, perturbation_parameter_sd=0)  # Votre fonction pour générer X, ajoutez les paramètres nécessaires\n",
    "    \n",
    "    # Calculer R_hat étendue avec phase\n",
    "    R_hat_with_phase = generate_R_hat_with_phase(X)\n",
    "    all_R_hat_with_phase[i] = R_hat_with_phase\n",
    "    \n",
    "    # Calculer les labels Z pour les angles générés\n",
    "    all_Z[i] = angles_to_binary_vector(thetaList, G)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, Z_train, Z_test = train_test_split(all_R_hat_with_phase, all_Z, test_size=0.1 , random_state=42)#test_size=0.1 selon papier\n",
    "\n",
    "#Conversion des données en tenseur\n",
    "X_train = torch.from_numpy(X_train).to(dtype=torch.float32)\n",
    "X_test = torch.from_numpy(X_test).to(dtype=torch.float32)\n",
    "Z_train = torch.from_numpy(Z_train).to(dtype=torch.float32)\n",
    "Z_test = torch.from_numpy(Z_test).to(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Création du dataset\n",
    "\n",
    "class DOADataset(Dataset):\n",
    "    def __init__(self, covariance_matrices, doa_labels):\n",
    "        \"\"\"\n",
    "        Initialisation du Dataset DOA.\n",
    "\n",
    "        Args:\n",
    "        - covariance_matrices (np.ndarray): Matrices de covariance étendues avec la phase.\n",
    "          Forme attendue: (nb_samples, nbSensors, nbSensors, 3) pour les parties réelle, imaginaire, et la phase.\n",
    "        - doa_labels (np.ndarray): Labels DOA sous forme de vecteurs binaires.\n",
    "          Forme attendue: (nb_samples, nb_labels), où nb_labels est le nombre de points dans la grille DOA.\n",
    "        \"\"\"\n",
    "        self.covariance_matrices = covariance_matrices\n",
    "        self.doa_labels = doa_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.covariance_matrices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      cov_matrix = self.covariance_matrices[idx]\n",
    "      angle = self.doa_labels[idx]\n",
    "\n",
    "      # Vérification si cov_matrix est déjà un ndarray, sinon le convertir\n",
    "      if not isinstance(cov_matrix, np.ndarray):\n",
    "          cov_matrix = cov_matrix.numpy()  # Convertir en tableau NumPy si ce n'est pas déjà fait\n",
    "    \n",
    "      cov_matrix = torch.from_numpy(cov_matrix).float()\n",
    "      angle = torch.tensor(angle).float()\n",
    "\n",
    "      return cov_matrix, angle\n",
    "\n",
    "\n",
    "# Exemple d'utilisation (remplacez R_hat_train/test et angles_train/test par vos données réelles)\n",
    "train_dataset = DOADataset(X_train, Z_train)\n",
    "test_dataset = DOADataset(X_test, Z_test)\n",
    "\n",
    "# Création des DataLoaders pour l'entraînement et le test, batch_size en fonction de l'article\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#Définition du device\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOACNN(\n",
      "  (conv1): Conv2d(3, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv7): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv10): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (relu6): ReLU()\n",
      "  (relu9): ReLU()\n",
      "  (relu12): ReLU()\n",
      "  (relu15): ReLU()\n",
      "  (relu18): ReLU()\n",
      "  (relu21): ReLU()\n",
      "  (dropout16): Dropout(p=0.2, inplace=False)\n",
      "  (dropout19): Dropout(p=0.2, inplace=False)\n",
      "  (dropout22): Dropout(p=0.2, inplace=False)\n",
      "  (flatten13): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc17): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc20): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc23): Linear(in_features=1024, out_features=121, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Définition du modèle\n",
    "nombre_de_classe=phi_max*2/rho+1\n",
    "nombre_de_classe=int(nombre_de_classe)\n",
    "class DOACNN(nn.Module):\n",
    "    def __init__(self, num_channels=3, num_classes=nombre_de_classe):\n",
    "        super(DOACNN, self).__init__()\n",
    "\n",
    "        # Couches convolutionnelles 2D\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, stride=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1)\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1)\n",
    "        self.conv10 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1)\n",
    "\n",
    "        # Normalisation de taille 256\n",
    "        self.norm2 = nn.BatchNorm2d(256)\n",
    "        self.norm5 = nn.BatchNorm2d(256)\n",
    "        self.norm8 = nn.BatchNorm2d(256)\n",
    "        self.norm11 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.relu3 =  nn.ReLU()\n",
    "        self.relu6 =  nn.ReLU()\n",
    "        self.relu9 =  nn.ReLU()\n",
    "        self.relu12 =  nn.ReLU()\n",
    "        self.relu15 =  nn.ReLU()\n",
    "        self.relu18 =  nn.ReLU()\n",
    "        self.relu21 =  nn.ReLU()\n",
    "\n",
    "        # Couches Dropout\n",
    "        self.dropout16 = nn.Dropout(0.2)\n",
    "        self.dropout19 = nn.Dropout(0.2)\n",
    "        self.dropout22 = nn.Dropout(0.2)\n",
    "\n",
    "        # Couche d'aplatissement\n",
    "        self.flatten13 = nn.Flatten()\n",
    "\n",
    "        # Couches entièrement connectées (FC)\n",
    "        self.fc14 = None\n",
    "        self.fc17 = nn.Linear(in_features=4096, out_features=2048)\n",
    "        self.fc20 = nn.Linear(in_features=2048, out_features=1024)\n",
    "        self.fc23 = nn.Linear(in_features=1024, out_features=num_classes)\n",
    "\n",
    "        # Couche de sortie Sigmoid\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"en entrée{x.shape}\")\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.norm5(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.norm8(x)\n",
    "        x = self.relu9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.norm11(x)\n",
    "        x = self.relu12(x)\n",
    "        x = self.flatten13(x)\n",
    "        self.fc14=nn.Linear(in_features=x.size(1), out_features=4096)\n",
    "        x = self.fc14(x)\n",
    "        x = self.relu15(x)\n",
    "        x = self.dropout16(x)\n",
    "        x = self.fc17(x)\n",
    "        x = self.relu18(x)\n",
    "        x = self.dropout19(x)\n",
    "        x = self.fc20(x)\n",
    "        x = self.relu21(x)\n",
    "        x = self.dropout22(x)\n",
    "        x = self.fc23(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Création d'une instance du modèle\n",
    "model = DOACNN()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Définition des hyperparamètres, choisis en fonction de l'article DOA estimator\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10 # à monter à 200 pour le training final selon l'article\n",
    "loss_fn = nn.BCELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boucle d'entraînement\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Display loss from time to time\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss: >7f}  [{current: >5d} / {size: >5d}]\")\n",
    "\n",
    "\n",
    "#Boucle de tests\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct, MSE = 0, 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            #print( f\"pred{pred.shape}\")\n",
    "            _, angles_predit = pred.topk(nbSources, dim=1)\n",
    "            _,angles_correct=top_values, top_indices = y.topk(nbSources, dim=1)\n",
    "            correct += (angles_predit==angles_correct).type(torch.float).sum().item()\n",
    "            #Calcul de la somme des carrés des différences entre prédictions et réalité pour la RMSE\n",
    "            taille_du_batch=pred.shape[0]\n",
    "            for element in range(taille_du_batch):\n",
    "                for angle in range(nbSources):\n",
    "                    MSE+=(angles_correct[element, angle]-angles_predit[element, angle])**2\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    MSE=MSE/(len(test_dataloader)*nbSources)\n",
    "    RMSE=math.sqrt(MSE)\n",
    "    print(f\"\\nTest set: \\n  Accuracy: {(100 * correct): >0.1f}%, Avg loss: {test_loss: >8f} \\n RMSE : {RMSE: >8f}\")\n",
    "    return test_loss, correct\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction d'entraînement et tests\n",
    "\n",
    "def train(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device):\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        test_loop(test_dataloader, model, loss_fn, device)\n",
    "        scheduler.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legra\\AppData\\Local\\Temp\\ipykernel_18396\\1795750363.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  angle = torch.tensor(angle).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "après densetorch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.692015  [   32 /   900]\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([4, 3, 16, 16])\n",
      "avant flattentorch.Size([4, 256, 4, 4])\n",
      "avant densetorch.Size([4, 4096])\n",
      "après densetorch.Size([4, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([4, 3, 16, 16])\n",
      "avant flattentorch.Size([4, 256, 4, 4])\n",
      "avant densetorch.Size([4, 4096])\n",
      "après densetorch.Size([4, 4096])\n",
      "\n",
      "Test set: \n",
      "  Accuracy: 3.0%, Avg loss: 0.087984 \n",
      " RMSE : 289.926284\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "loss: 0.091098  [   32 /   900]\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([4, 3, 16, 16])\n",
      "avant flattentorch.Size([4, 256, 4, 4])\n",
      "avant densetorch.Size([4, 4096])\n",
      "après densetorch.Size([4, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([4, 3, 16, 16])\n",
      "avant flattentorch.Size([4, 256, 4, 4])\n",
      "avant densetorch.Size([4, 4096])\n",
      "après densetorch.Size([4, 4096])\n",
      "\n",
      "Test set: \n",
      "  Accuracy: 0.0%, Avg loss: 0.087581 \n",
      " RMSE : 351.632265\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "loss: 0.086840  [   32 /   900]\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([4, 3, 16, 16])\n",
      "avant flattentorch.Size([4, 256, 4, 4])\n",
      "avant densetorch.Size([4, 4096])\n",
      "après densetorch.Size([4, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([4, 3, 16, 16])\n",
      "avant flattentorch.Size([4, 256, 4, 4])\n",
      "avant densetorch.Size([4, 4096])\n",
      "après densetorch.Size([4, 4096])\n",
      "\n",
      "Test set: \n",
      "  Accuracy: 3.0%, Avg loss: 0.088526 \n",
      " RMSE : 214.542537\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "loss: 0.090863  [   32 /   900]\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n",
      "en entréetorch.Size([32, 3, 16, 16])\n",
      "avant flattentorch.Size([32, 256, 4, 4])\n",
      "avant densetorch.Size([32, 4096])\n",
      "après densetorch.Size([32, 4096])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[319], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntraînement terminé!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[318], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     test_loop(test_dataloader, model, loss_fn, device)\n\u001b[0;32m      8\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[317], line 19\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 19\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Display loss from time to time\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    158\u001b[0m         group,\n\u001b[0;32m    159\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    164\u001b[0m         state_steps)\n\u001b[1;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs, device)\n",
    "print('Entraînement terminé!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en entréetorch.Size([1, 3, 9, 9])\n",
      "avant flattentorch.Size([1, 256, 1, 1])\n",
      "avant densetorch.Size([1, 256])\n",
      "après densetorch.Size([1, 4096])\n",
      "tensor([[0.0000e+00, 1.8807e-26, 2.2443e-18, 3.7667e-20, 2.0078e-24, 2.4823e-35,\n",
      "         2.2030e-19, 8.1689e-19, 5.7784e-10, 3.0382e-25, 2.3879e-08, 2.6150e-05,\n",
      "         2.8408e-15, 1.5090e-12, 3.5441e-15, 4.2752e-13, 9.4271e-14, 2.7394e-17,\n",
      "         3.5821e-25, 1.2741e-24, 1.3296e-29, 1.5004e-23, 3.6175e-32, 7.7476e-30,\n",
      "         2.6099e-35, 8.5039e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5668e-37,\n",
      "         0.0000e+00, 1.2746e-19, 2.6642e-29, 2.4826e-37, 1.2585e-36, 4.7082e-31,\n",
      "         4.7305e-32, 1.3210e-31, 2.2967e-32, 2.2722e-33, 7.7288e-34, 9.9485e-37,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         4.3921e-38, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.1372e-36, 0.0000e+00, 4.8055e-38, 4.5564e-29,\n",
      "         0.0000e+00, 0.0000e+00, 7.0995e-37, 1.4965e-29, 8.6481e-37, 6.0403e-31,\n",
      "         3.2356e-38, 0.0000e+00, 0.0000e+00, 1.7375e-31, 0.0000e+00, 2.5966e-37,\n",
      "         7.2776e-39, 2.7461e-32, 0.0000e+00, 3.0230e-36, 0.0000e+00, 2.6783e-31,\n",
      "         1.2984e-29, 6.1334e-34, 3.5983e-28, 1.1090e-27, 1.2170e-33, 1.0291e-28,\n",
      "         8.3577e-25, 0.0000e+00, 0.0000e+00, 3.0918e-34, 3.0717e-30, 0.0000e+00,\n",
      "         0.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[10, 11]])\n"
     ]
    }
   ],
   "source": [
    "x= generate_X_matrix(nbSources, L, T, [-59,59], [1], correlation_List, 20, perturbation_parameter_sd=0)\n",
    "R_hat_with_phase = generate_R_hat_with_phase(x)\n",
    "X_train = torch.from_numpy(R_hat_with_phase).to(dtype=torch.float32)\n",
    "X_train=X_train.unsqueeze(0)\n",
    "angle_predit=model(X_train)\n",
    "print(angle_predit)\n",
    "_, angles_predit = angle_predit.topk(nbSources, dim=1)\n",
    "sorted_angles, _ = torch.sort(angles_predit)\n",
    "print(sorted_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOACNN(\n",
      "  (conv1): Conv2d(3, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv7): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv10): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (relu6): ReLU()\n",
      "  (relu9): ReLU()\n",
      "  (relu12): ReLU()\n",
      "  (relu15): ReLU()\n",
      "  (relu18): ReLU()\n",
      "  (relu21): ReLU()\n",
      "  (dropout16): Dropout(p=0.2, inplace=False)\n",
      "  (dropout19): Dropout(p=0.2, inplace=False)\n",
      "  (dropout22): Dropout(p=0.2, inplace=False)\n",
      "  (flatten13): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc14): Linear(in_features=256, out_features=4096, bias=True)\n",
      "  (fc17): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc20): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc23): Linear(in_features=1024, out_features=121, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "en entréetorch.Size([2, 3, 9, 9])\n",
      "avant flattentorch.Size([2, 256, 1, 1])\n",
      "avant densetorch.Size([2, 256])\n",
      "après densetorch.Size([2, 4096])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 256, 4, 4]           7,168\n",
      "       BatchNorm2d-2            [-1, 256, 4, 4]             512\n",
      "              ReLU-3            [-1, 256, 4, 4]               0\n",
      "            Conv2d-4            [-1, 256, 3, 3]         262,400\n",
      "       BatchNorm2d-5            [-1, 256, 3, 3]             512\n",
      "              ReLU-6            [-1, 256, 3, 3]               0\n",
      "            Conv2d-7            [-1, 256, 2, 2]         262,400\n",
      "       BatchNorm2d-8            [-1, 256, 2, 2]             512\n",
      "              ReLU-9            [-1, 256, 2, 2]               0\n",
      "           Conv2d-10            [-1, 256, 1, 1]         262,400\n",
      "      BatchNorm2d-11            [-1, 256, 1, 1]             512\n",
      "             ReLU-12            [-1, 256, 1, 1]               0\n",
      "          Flatten-13                  [-1, 256]               0\n",
      "           Linear-14                 [-1, 4096]       1,052,672\n",
      "             ReLU-15                 [-1, 4096]               0\n",
      "          Dropout-16                 [-1, 4096]               0\n",
      "           Linear-17                 [-1, 2048]       8,390,656\n",
      "             ReLU-18                 [-1, 2048]               0\n",
      "          Dropout-19                 [-1, 2048]               0\n",
      "           Linear-20                 [-1, 1024]       2,098,176\n",
      "             ReLU-21                 [-1, 1024]               0\n",
      "          Dropout-22                 [-1, 1024]               0\n",
      "           Linear-23                  [-1, 121]         124,025\n",
      "          Sigmoid-24                  [-1, 121]               0\n",
      "================================================================\n",
      "Total params: 12,461,945\n",
      "Trainable params: 12,461,945\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.34\n",
      "Params size (MB): 47.54\n",
      "Estimated Total Size (MB): 47.88\n",
      "----------------------------------------------------------------\n",
      "Layer: conv1.weight | Size: torch.Size([256, 3, 3, 3])\n",
      "Layer: conv1.bias | Size: torch.Size([256])\n",
      "Layer: conv4.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv4.bias | Size: torch.Size([256])\n",
      "Layer: conv7.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv7.bias | Size: torch.Size([256])\n",
      "Layer: conv10.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv10.bias | Size: torch.Size([256])\n",
      "Layer: norm2.weight | Size: torch.Size([256])\n",
      "Layer: norm2.bias | Size: torch.Size([256])\n",
      "Layer: norm5.weight | Size: torch.Size([256])\n",
      "Layer: norm5.bias | Size: torch.Size([256])\n",
      "Layer: norm8.weight | Size: torch.Size([256])\n",
      "Layer: norm8.bias | Size: torch.Size([256])\n",
      "Layer: norm11.weight | Size: torch.Size([256])\n",
      "Layer: norm11.bias | Size: torch.Size([256])\n",
      "Layer: fc14.weight | Size: torch.Size([4096, 256])\n",
      "Layer: fc14.bias | Size: torch.Size([4096])\n",
      "Layer: fc17.weight | Size: torch.Size([2048, 4096])\n",
      "Layer: fc17.bias | Size: torch.Size([2048])\n",
      "Layer: fc20.weight | Size: torch.Size([1024, 2048])\n",
      "Layer: fc20.bias | Size: torch.Size([1024])\n",
      "Layer: fc23.weight | Size: torch.Size([121, 1024])\n",
      "Layer: fc23.bias | Size: torch.Size([121])\n"
     ]
    }
   ],
   "source": [
    "#Quelques informations sur notre modèle : \n",
    "\n",
    "print(model)\n",
    "\n",
    "summary(model, input_size=(3, nbSensors, nbSensors))\n",
    "\n",
    "#Poids des paramètres :\n",
    "\n",
    "\n",
    "# Initialiser le compteur de paramètres\n",
    "total_params = 0\n",
    "\n",
    "# Boucle à travers les paramètres de votre modèle\n",
    "for param in model.parameters():\n",
    "    # Vérifier si le paramètre nécessite un gradient (c'est-à-dire s'il est entraînable)\n",
    "    if param.requires_grad:\n",
    "        # Compter le nombre de valeurs dans le paramètre\n",
    "        total_params += param.numel()\n",
    "\n",
    "# Boucle à travers les paramètres de votre modèle\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#On sauvegarde le modèle pour l\\'utiliser dans un autre module python\\nfrom Models.compare import *\\nsave_model_hyperparams_and_metadata(model, hyperparameters=[{\"A\" : \"a\"}], training_metadata=[{\"A\" : \"a\"}], directory_name=\"DaO_estimator\")\\n'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#On sauvegarde le modèle pour l'utiliser dans un autre module python\n",
    "from Models.compare import *\n",
    "save_model_hyperparams_and_metadata(model, hyperparameters=[{\"A\" : \"a\"}], training_metadata=[{\"A\" : \"a\"}], directory_name=\"DaO_estimator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model_and_hyperparams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[265], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m DaO_model,_\u001b[38;5;241m=\u001b[39m\u001b[43mload_model_and_hyperparams\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDaO_estimator\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_class\u001b[38;5;241m=\u001b[39mDOACNN)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mDaO_method\u001b[39m(X,nbSensors, nbSources):\n\u001b[0;32m      3\u001b[0m     R_hat_with_phase \u001b[38;5;241m=\u001b[39m generate_R_hat_with_phase(X)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model_and_hyperparams' is not defined"
     ]
    }
   ],
   "source": [
    "DaO_model,_=load_model_and_hyperparams(\"DaO_estimator\", model_class=DOACNN)\n",
    "def DaO_method(X,nbSensors, nbSources):\n",
    "    R_hat_with_phase = generate_R_hat_with_phase(X)\n",
    "    X_train = torch.from_numpy(R_hat_with_phase).to(dtype=torch.float32)\n",
    "    X_train=X_train.unsqueeze(0)\n",
    "    pred=DaO_model(X_train)\n",
    "    _, angles_predit = pred.topk(nbSources, dim=1)\n",
    "    sorted_angles, _ = torch.sort(angles_predit)\n",
    "    return list(sorted_angles)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([72, 74])]\n"
     ]
    }
   ],
   "source": [
    "x= generate_X_matrix(nbSources, L, T, [-10,10], [1], correlation_List, 20, perturbation_parameter_sd=0)\n",
    "angle_predit=DaO_method(x,nbSensors,nbSources)\n",
    "print(angle_predit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPuis voici la marche à suivre pour charger le modèle entrainé dans un nouveau module python\\n\\nimport torch\\nimport torch.nn as nn\\n\\n# Définir la classe de votre modèle (avec la même architecture que celle utilisée pour l'entraînement)\\nclass VotreModele(nn.Module):\\n    def __init__(self, ...):  # Définir les mêmes couches que celles utilisées pour l'entraînement\\n        super(VotreModele, self).__init__()\\n        ...\\n\\n# Créer une instance de votre modèle\\nmodel = VotreModele(...)\\n\\n# Charger les poids du modèle entraîné\\nmodel.load_state_dict(torch.load('chemin/vers/votre/modele.pth'))\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sauvegarder le modèle pour l'utiliser dans un autre module python:\n",
    "#torch.save(model.state_dict(), 'C:\\\\Users\\\\legra\\\\Documents pc\\\\ENSAI\\\\3A\\\\PFE\\\\model.pth')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Puis voici la marche à suivre pour charger le modèle entrainé dans un nouveau module python\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Définir la classe de votre modèle (avec la même architecture que celle utilisée pour l'entraînement)\n",
    "class VotreModele(nn.Module):\n",
    "    def __init__(self, ...):  # Définir les mêmes couches que celles utilisées pour l'entraînement\n",
    "        super(VotreModele, self).__init__()\n",
    "        ...\n",
    "\n",
    "# Créer une instance de votre modèle\n",
    "model = VotreModele(...)\n",
    "\n",
    "# Charger les poids du modèle entraîné\n",
    "model.load_state_dict(torch.load('chemin/vers/votre/modele.pth'))\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test du modèle complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generate_X_matrix() missing 1 required positional argument: 'perturbation_parameter_sd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m thetaList_complex \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39mphi_max, phi_max) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nbSources)]  \u001b[38;5;66;03m# Exemple de génération d'angles\u001b[39;00m\n\u001b[0;32m     10\u001b[0m varList_complex \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1000000000000\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nbSources)]\n\u001b[1;32m---> 11\u001b[0m X_complex \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_X_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbSources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthetaList_complex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvarList_complex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrelation_List\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal_noise_ratio\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Votre fonction pour générer X, ajoutez les paramètres nécessaires\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calculer R_hat étendue avec phase\u001b[39;00m\n\u001b[0;32m     14\u001b[0m R_hat_with_phase_complex \u001b[38;5;241m=\u001b[39m generate_R_hat_with_phase_complex(X_complex)\n",
      "\u001b[1;31mTypeError\u001b[0m: generate_X_matrix() missing 1 required positional argument: 'perturbation_parameter_sd'"
     ]
    }
   ],
   "source": [
    "#Génération des données\n",
    "\n",
    "# Initialisation des tableaux pour les données\n",
    "all_R_hat_with_phase_complex = np.zeros((num_samples, 2, L, L))\n",
    "all_Z_complex = np.zeros((num_samples, len(G)))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Générer les angles d'arrivée et la matrice X comme décrit précédemment\n",
    "    thetaList_complex = [np.random.uniform(-phi_max, phi_max) for _ in range(nbSources)]  # Exemple de génération d'angles\n",
    "    varList_complex = [np.random.uniform(0, 1000000000000) for _ in range(nbSources)]\n",
    "    X_complex = generate_X_matrix(nbSources, L, T, thetaList_complex, varList_complex, correlation_List, signal_noise_ratio)  # Votre fonction pour générer X, ajoutez les paramètres nécessaires\n",
    "    \n",
    "    # Calculer R_hat étendue avec phase\n",
    "    R_hat_with_phase_complex = generate_R_hat_with_phase_complex(X_complex)\n",
    "    all_R_hat_with_phase_complex[i] = R_hat_with_phase_complex\n",
    "    \n",
    "    # Calculer les labels Z pour les angles générés\n",
    "    all_Z_complex[i] = angles_to_binary_vector(thetaList_complex, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train_complex, X_test_complex, Z_train_complex, Z_test_complex = train_test_split(all_R_hat_with_phase_complex, all_Z_complex, test_size=0.1 , random_state=42)#test_size=0.1 selon papier\n",
    "\n",
    "#Conversion des données en tenseur\n",
    "X_train_complex = torch.from_numpy(X_train_complex).to(dtype=torch.complex64)\n",
    "X_test_complex = torch.from_numpy(X_test_complex).to(dtype=torch.complex64)\n",
    "Z_train_complex = torch.from_numpy(Z_train_complex).to(dtype=torch.complex64)\n",
    "Z_test_complex = torch.from_numpy(Z_test_complex).to(dtype=torch.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du dataset\n",
    "\n",
    "class DOADatasetComplex(Dataset):\n",
    "    def __init__(self, covariance_matrices, doa_labels):\n",
    "        \"\"\"\n",
    "        Initialisation du Dataset DOA.\n",
    "\n",
    "        Args:\n",
    "        - covariance_matrices (np.ndarray): Matrices de covariance étendues avec la phase.\n",
    "          Forme attendue: (nb_samples, nbSensors, nbSensors, 3) pour les parties réelle, imaginaire, et la phase.\n",
    "        - doa_labels (np.ndarray): Labels DOA sous forme de vecteurs binaires.\n",
    "          Forme attendue: (nb_samples, nb_labels), où nb_labels est le nombre de points dans la grille DOA.\n",
    "        \"\"\"\n",
    "        self.covariance_matrices = covariance_matrices\n",
    "        self.doa_labels = doa_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.covariance_matrices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      cov_matrix = self.covariance_matrices[idx]\n",
    "      angle = self.doa_labels[idx]\n",
    "\n",
    "      # Vérification si cov_matrix est déjà un ndarray, sinon le convertir\n",
    "      if not isinstance(cov_matrix, np.ndarray):\n",
    "          cov_matrix = cov_matrix.numpy()  # Convertir en tableau NumPy si ce n'est pas déjà fait\n",
    "    \n",
    "      cov_matrix = torch.from_numpy(cov_matrix).to(dtype=torch.complex64)\n",
    "      angle = torch.tensor(angle).to(dtype=torch.complex64)\n",
    "\n",
    "      return cov_matrix, angle\n",
    "\n",
    "\n",
    "# Exemple d'utilisation (remplacez R_hat_train/test et angles_train/test par vos données réelles)\n",
    "train_dataset_complex = DOADatasetComplex(X_train_complex, Z_train_complex)\n",
    "test_dataset_complex = DOADatasetComplex(X_test_complex, Z_test_complex)\n",
    "\n",
    "# Création des DataLoaders pour l'entraînement et le test, batch_size en fonction de l'article\n",
    "train_dataloader_complex = DataLoader(train_dataset_complex, batch_size=32, shuffle=True)\n",
    "test_dataloader_complex = DataLoader(test_dataset_complex, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOACNNCOMPLEX(\n",
      "  (conv1): Conv2d(2, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv7): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv10): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (relu6): ReLU()\n",
      "  (relu9): ReLU()\n",
      "  (relu12): ReLU()\n",
      "  (relu15): ReLU()\n",
      "  (relu18): ReLU()\n",
      "  (relu21): ReLU()\n",
      "  (dropout16): Dropout(p=0.2, inplace=False)\n",
      "  (dropout19): Dropout(p=0.2, inplace=False)\n",
      "  (dropout22): Dropout(p=0.2, inplace=False)\n",
      "  (flatten13): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc14): Linear(in_features=256, out_features=4096, bias=True)\n",
      "  (fc17): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc20): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc23): Linear(in_features=1024, out_features=91, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Définition du modèle\n",
    "\n",
    "class DOACNNCOMPLEX(nn.Module):\n",
    "    def __init__(self, num_channels=2, num_classes=phi_max*2+1):\n",
    "        super(DOACNNCOMPLEX, self).__init__()\n",
    "\n",
    "        # Couches convolutionnelles 2D\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=256, kernel_size=3, stride=2, bias=True)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1, bias=True)\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1, bias=True)\n",
    "        self.conv10 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=2, stride=1, bias=True)\n",
    "\n",
    "        # Normalisation de taille 256\n",
    "        self.norm2 = nn.BatchNorm2d(256)\n",
    "        self.norm5 = nn.BatchNorm2d(256)\n",
    "        self.norm8 = nn.BatchNorm2d(256)\n",
    "        self.norm11 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.relu3 =  nn.ReLU()\n",
    "        self.relu6 =  nn.ReLU()\n",
    "        self.relu9 =  nn.ReLU()\n",
    "        self.relu12 =  nn.ReLU()\n",
    "        self.relu15 =  nn.ReLU()\n",
    "        self.relu18 =  nn.ReLU()\n",
    "        self.relu21 =  nn.ReLU()\n",
    "\n",
    "        # Couches Dropout\n",
    "        self.dropout16 = nn.Dropout(0.2)\n",
    "        self.dropout19 = nn.Dropout(0.2)\n",
    "        self.dropout22 = nn.Dropout(0.2)\n",
    "\n",
    "        # Couche d'aplatissement\n",
    "        self.flatten13 = nn.Flatten()\n",
    "\n",
    "        # Couches entièrement connectées (FC)\n",
    "        self.fc14 = nn.Linear(in_features=256 , out_features=4096)\n",
    "        self.fc17 = nn.Linear(in_features=4096, out_features=2048)\n",
    "        self.fc20 = nn.Linear(in_features=2048, out_features=1024)\n",
    "        self.fc23 = nn.Linear(in_features=1024, out_features=num_classes)\n",
    "\n",
    "        # Couche de sortie Sigmoid\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.norm5(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.norm8(x)\n",
    "        x = self.relu9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.norm11(x)\n",
    "        x = self.relu12(x)\n",
    "        x = self.flatten13(x)\n",
    "        x = self.fc14(x)\n",
    "        x = self.relu15(x)\n",
    "        x = self.dropout16(x)\n",
    "        x = self.fc17(x)\n",
    "        x = self.relu18(x)\n",
    "        x = self.dropout19(x)\n",
    "        x = self.fc20(x)\n",
    "        x = self.relu21(x)\n",
    "        x = self.dropout22(x)\n",
    "        x = self.fc23(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Création d'une instance du modèle\n",
    "modelComplex = DOACNNCOMPLEX()\n",
    "print(modelComplex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\legra\\AppData\\Local\\Temp\\ipykernel_25528\\3472206976.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  angle = torch.tensor(angle).to(dtype=torch.complex64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (struct c10::complex<float>) and bias type (float) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelComplex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader_complex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader_complex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntraînement terminé!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, test_dataloader, loss_fn, optimizer, epochs, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     test_loop(test_dataloader, model, loss_fn, device)\n\u001b[0;32m      8\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Compute prediction and loss\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 45\u001b[0m, in \u001b[0;36mDOACNNCOMPLEX.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 45\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)\n\u001b[0;32m     47\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu3(x)\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\legra\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (struct c10::complex<float>) and bias type (float) should be the same"
     ]
    }
   ],
   "source": [
    "train(modelComplex, train_dataloader_complex, test_dataloader_complex, loss_fn, optimizer, num_epochs, device)\n",
    "print('Entraînement terminé!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOACNNCOMPLEX(\n",
      "  (conv1): Conv2d(2, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv7): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv10): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (norm11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (relu6): ReLU()\n",
      "  (relu9): ReLU()\n",
      "  (relu12): ReLU()\n",
      "  (relu15): ReLU()\n",
      "  (relu18): ReLU()\n",
      "  (relu21): ReLU()\n",
      "  (dropout16): Dropout(p=0.2, inplace=False)\n",
      "  (dropout19): Dropout(p=0.2, inplace=False)\n",
      "  (dropout22): Dropout(p=0.2, inplace=False)\n",
      "  (flatten13): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc14): Linear(in_features=256, out_features=4096, bias=True)\n",
      "  (fc17): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc20): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc23): Linear(in_features=1024, out_features=91, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 256, 4, 4]           4,864\n",
      "       BatchNorm2d-2            [-1, 256, 4, 4]             512\n",
      "              ReLU-3            [-1, 256, 4, 4]               0\n",
      "            Conv2d-4            [-1, 256, 3, 3]         262,400\n",
      "       BatchNorm2d-5            [-1, 256, 3, 3]             512\n",
      "              ReLU-6            [-1, 256, 3, 3]               0\n",
      "            Conv2d-7            [-1, 256, 2, 2]         262,400\n",
      "       BatchNorm2d-8            [-1, 256, 2, 2]             512\n",
      "              ReLU-9            [-1, 256, 2, 2]               0\n",
      "           Conv2d-10            [-1, 256, 1, 1]         262,400\n",
      "      BatchNorm2d-11            [-1, 256, 1, 1]             512\n",
      "             ReLU-12            [-1, 256, 1, 1]               0\n",
      "          Flatten-13                  [-1, 256]               0\n",
      "           Linear-14                 [-1, 4096]       1,052,672\n",
      "             ReLU-15                 [-1, 4096]               0\n",
      "          Dropout-16                 [-1, 4096]               0\n",
      "           Linear-17                 [-1, 2048]       8,390,656\n",
      "             ReLU-18                 [-1, 2048]               0\n",
      "          Dropout-19                 [-1, 2048]               0\n",
      "           Linear-20                 [-1, 1024]       2,098,176\n",
      "             ReLU-21                 [-1, 1024]               0\n",
      "          Dropout-22                 [-1, 1024]               0\n",
      "           Linear-23                   [-1, 91]          93,275\n",
      "          Sigmoid-24                   [-1, 91]               0\n",
      "================================================================\n",
      "Total params: 12,428,891\n",
      "Trainable params: 12,428,891\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.34\n",
      "Params size (MB): 47.41\n",
      "Estimated Total Size (MB): 47.76\n",
      "----------------------------------------------------------------\n",
      "Layer: conv1.weight | Size: torch.Size([256, 2, 3, 3])\n",
      "Layer: conv1.bias | Size: torch.Size([256])\n",
      "Layer: conv4.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv4.bias | Size: torch.Size([256])\n",
      "Layer: conv7.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv7.bias | Size: torch.Size([256])\n",
      "Layer: conv10.weight | Size: torch.Size([256, 256, 2, 2])\n",
      "Layer: conv10.bias | Size: torch.Size([256])\n",
      "Layer: norm2.weight | Size: torch.Size([256])\n",
      "Layer: norm2.bias | Size: torch.Size([256])\n",
      "Layer: norm5.weight | Size: torch.Size([256])\n",
      "Layer: norm5.bias | Size: torch.Size([256])\n",
      "Layer: norm8.weight | Size: torch.Size([256])\n",
      "Layer: norm8.bias | Size: torch.Size([256])\n",
      "Layer: norm11.weight | Size: torch.Size([256])\n",
      "Layer: norm11.bias | Size: torch.Size([256])\n",
      "Layer: fc14.weight | Size: torch.Size([4096, 256])\n",
      "Layer: fc14.bias | Size: torch.Size([4096])\n",
      "Layer: fc17.weight | Size: torch.Size([2048, 4096])\n",
      "Layer: fc17.bias | Size: torch.Size([2048])\n",
      "Layer: fc20.weight | Size: torch.Size([1024, 2048])\n",
      "Layer: fc20.bias | Size: torch.Size([1024])\n",
      "Layer: fc23.weight | Size: torch.Size([91, 1024])\n",
      "Layer: fc23.bias | Size: torch.Size([91])\n"
     ]
    }
   ],
   "source": [
    "#Quelques informations sur notre modèle : \n",
    "\n",
    "print(modelComplex)\n",
    "\n",
    "summary(modelComplex, input_size=(2, nbSensors, nbSensors))\n",
    "\n",
    "#Poids des paramètres :\n",
    "\n",
    "\n",
    "# Initialiser le compteur de paramètres\n",
    "total_params_complex = 0\n",
    "\n",
    "# Boucle à travers les paramètres de votre modèle\n",
    "for param in modelComplex.parameters():\n",
    "    # Vérifier si le paramètre nécessite un gradient (c'est-à-dire s'il est entraînable)\n",
    "    if param.requires_grad:\n",
    "        # Compter le nombre de valeurs dans le paramètre\n",
    "        total_params_complex += param.numel()\n",
    "\n",
    "# Boucle à travers les paramètres de votre modèle\n",
    "for name, param in modelComplex.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
